WEBVTT

1
00:00:00.000 --> 00:00:02.610
だから、あなただけの最後に到達しようとしています

2
00:00:02.610 --> 00:00:06.165
この専門分野での最初のコース上の材料の最初の週。

3
00:00:06.165 --> 00:00:09.960
私はあなたにあなたにも、今後数週間のうちに学ぶ何の迅速な感覚を与えてみましょう。

4
00:00:09.960 --> 00:00:12.000
私は、最初のビデオで言ったように、

5
00:00:12.000 --> 00:00:15.150
この専門は5つのコースを備えています。

6
00:00:15.150 --> 00:00:17.250
そして今、我々は最初にしています

7
00:00:17.250 --> 00:00:20.385
あなたの最も重要な基礎を教えるこれらの5つのコース、

8
00:00:20.385 --> 00:00:23.745
深い学習の本当に最も重要なビルディング・ブロック。

9
00:00:23.745 --> 00:00:25.530
したがって、この最初のコースの終わりまでに、

10
00:00:25.530 --> 00:00:30.350
あなたは深いニューラルネットワークを動作するように構築し、取得する方法を知っています。

11
00:00:30.350 --> 00:00:33.780
そこでここでは、この最初のコースにあるものの詳細が表示されます。

12
00:00:33.780 --> 00:00:35.725
このコースでは、材料の4週間です。

13
00:00:35.725 --> 00:00:37.620
そして、あなただけの最後まで来ています

14
00:00:37.620 --> 00:00:40.110
あなたが深い学習への導入を見た最初の週。

15
00:00:40.110 --> 00:00:41.530
毎週の終わりに、

16
00:00:41.530 --> 00:00:44.190
その10多肢選択問題であることもあります

17
00:00:44.190 --> 00:00:47.495
あなたは、材料のご理解を再確認するために使用することができます。

18
00:00:47.495 --> 00:00:49.185
だから、あなたはこのビデオを見終わったときに、

19
00:00:49.185 --> 00:00:51.860
私はあなたがこれらの質問を見てみるつもりだ願っています。

20
00:00:51.860 --> 00:00:56.530
二週目では、あなたは、ニューラルネットワークプログラミングの基礎を学びます。

21
00:00:56.530 --> 00:00:58.420
あなたは私たちの構造を学びます

22
00:00:58.420 --> 00:01:00.960
前方に伝播し、バックプロパゲーションを呼び出します

23
00:01:00.960 --> 00:01:06.030
アルゴリズムのステップとどのように効率的にニューラルネットワークを実装します。

24
00:01:06.030 --> 00:01:07.405
第二週から始まって、

25
00:01:07.405 --> 00:01:10.125
あなたはまた、プログラミング演習を行うために取得します

26
00:01:10.125 --> 00:01:13.605
それは、あなたがちょうど学んだ材料を練習することができます

27
00:01:13.605 --> 00:01:16.735
アルゴリズムを自分で実装し、それが自分のために働くご覧ください。

28
00:01:16.735 --> 00:01:19.550
私は、アルゴリズムと、彼らを学ぶとき、私はそれが本当に満足見つけます

29
00:01:19.550 --> 00:01:22.375
それがアップコード化されたと私はそれが自分のために働い見ます。

30
00:01:22.375 --> 00:01:24.080
だから私は、あなたがあまりにもすることをお楽しみください。

31
00:01:24.080 --> 00:01:28.140
第3週に、ニューラルネットワークプログラミングのためのフレームワークを学びました、

32
00:01:28.140 --> 00:01:32.050
あなたは、単一の隠れ層のニューラルネットワークをコーディングします。大丈夫。

33
00:01:32.050 --> 00:01:34.470
だから、必要なすべての主要な概念を学びます

34
00:01:34.470 --> 00:01:37.005
実装し、ニューラルネットワークで動作するように取得します。

35
00:01:37.005 --> 00:01:38.485
そして、最終的には4週では、

36
00:01:38.485 --> 00:01:41.175
あなたと深いニューラルネットワークとニューラルネットワークを構築

37
00:01:41.175 --> 00:01:44.081
多くの層と、それはあなた自身のために働いていた参照してください。

38
00:01:44.081 --> 00:01:47.930
だから、この1の後にビデオを終えおめでとうございます。

39
00:01:47.930 --> 00:01:51.600
私はあなたが今、深い学習で何が起こっているかの良いハイレベルセンスを持っていることを願っています。

40
00:01:51.600 --> 00:01:53.610
そして、おそらくあなたのいくつかは、また、に割り当てられ、

41
00:01:53.610 --> 00:01:57.355
あなた自身の学習を深く適用したい場合がありますどこのいくつかのアイデアを持っています。

42
00:01:57.355 --> 00:01:59.370
だから、私はこのビデオの後に願って、

43
00:01:59.370 --> 00:02:03.850
あなたはこのビデオをたどる10問の選択問題を見てみるために行きます

44
00:02:03.850 --> 00:02:05.500
コースのウェブサイトとだけ使用上の

45
00:02:05.500 --> 00:02:08.760
ご理解を確認するための10問の選択問題。

46
00:02:08.760 --> 00:02:11.199
そして、確認していない、あなたは、すべての答えを右に初めてを得ることはありません

47
00:02:11.199 --> 00:02:14.710
あなたがそれらすべての権利を取得するまで、あなたは何度も何度も試すことができます。

48
00:02:14.710 --> 00:02:19.145
私は、私はすべての概念を理解していていることを確認するためにそれらが有用であることが判明しました

49
00:02:19.145 --> 00:02:21.465
私はあなたがあまりにもそのようにしている願っています。

50
00:02:21.465 --> 00:02:24.000
だからで、最大取得するために再びおめでとう

51
00:02:24.000 --> 00:02:27.670
ここで、私は週に2曲のビデオであなたをお待ちしております。

52
00:02:11.580 --> 00:02:16.409
入力画像は60であります

53
00:02:13.290 --> 00:02:20.969
64個のピクセル×4つのピクセルあなたが希望

54
00:02:16.409 --> 00:02:24.060
3 64×64のマトリクスを持っています

55
00:02:20.969 --> 00:02:26.489
赤、緑、青に対応します

56
00:02:24.060 --> 00:02:28.920
あなたの画像のピクセル強度値

57
00:02:26.489 --> 00:02:31.200
スライドIからこれらを作るものの、

58
00:02:28.920 --> 00:02:33.299
ので、これらのようにはるかに小さいの行列を描きました

59
00:02:31.200 --> 00:02:36.629
これらは、実際には5×4行列であります

60
00:02:33.299 --> 00:02:39.930
ので、これらを有効にする64によってではなく、64

61
00:02:36.629 --> 00:02:42.810
特徴に画素強度値

62
00:02:39.930 --> 00:02:46.260
私たちがやろうとしているどのようなベクトルはアンロールです

63
00:02:42.810 --> 00:02:50.609
入力へのこれらのピクセル値の全て

64
00:02:46.260 --> 00:02:52.739
のすべてをアンロールするので、特徴ベクトルX

65
00:02:50.609 --> 00:02:55.290
これらの画素強度値

66
00:02:52.739 --> 00:02:58.560
私たちがやろうとしているどのような特徴ベクトルがあります

67
00:02:55.290 --> 00:03:00.299
対応する特徴ベクトルXを定義します

68
00:02:58.560 --> 00:03:03.060
この次元にある次のように

69
00:03:00.299 --> 00:03:08.220
全ての画素値2 5を取るつもり

70
00:03:03.060 --> 00:03:10.620
2 3 1、SO 2 3 1 2 5に等

71
00:03:08.220 --> 00:03:14.459
我々は、すべての赤色画素をリストアップしましたまで

72
00:03:10.620 --> 00:03:17.459
そして、最終的に5 1 2 3 4 5 1

73
00:03:14.459 --> 00:03:20.400
3 4というように、私たちは非常に長いを得るまで

74
00:03:17.459 --> 00:03:24.150
特徴ベクトルは、すべての赤をリストアップ

75
00:03:20.400 --> 00:03:28.680
緑及び青の画素強度値

76
00:03:24.150 --> 00:03:32.190
この画像この画像はで64であるかのように、

77
00:03:28.680 --> 00:03:37.260
64イメージこの合計寸法

78
00:03:32.190 --> 00:03:40.139
ベクトルXは3で64で64になりますので、

79
00:03:37.260 --> 00:03:42.900
総数ことを、私たちは、すべての中に持っています

80
00:03:40.139 --> 00:03:45.479
この場合には、これらの行列になります

81
00:03:42.900 --> 00:03:47.519
アウトあなたが得るものです1 2 2 8 8されるように

82
00:03:45.479 --> 00:03:51.269
あなたはこれらの数字を乗算し、そうであれば

83
00:03:47.519 --> 00:03:53.729
私たちは、1 2 2 8 8に等しいn個のXを使用するつもりです

84
00:03:51.269 --> 00:03:56.430
入力の大きさを表すために

85
00:03:53.729 --> 00:03:59.849
X時には簡潔にするための機能と

86
00:03:56.430 --> 00:04:01.919
また、単に表現するために、小文字のnを使用します

87
00:03:59.849 --> 00:04:02.459
この入力機能の次元

88
00:04:01.919 --> 00:04:05.310
ベクター

89
00:04:02.459 --> 00:04:07.319
そうバイナリ分類で私たちの目標です

90
00:04:05.310 --> 00:04:09.419
入力ANをすることができます分類器を学ぶために

91
00:04:07.319 --> 00:04:13.650
この特徴ベクトルによって表される画像

92
00:04:09.419 --> 00:04:16.590
Xと対応するかどうかを予測

93
00:04:13.650 --> 00:04:19.109
ラベルYはこのかどうかである1または0であります

94
00:04:16.590 --> 00:04:21.060
猫の画像や非猫の画像は、してみましょうさ

95
00:04:19.109 --> 00:04:22.680
今その表記法の一部をレイアウト

96
00:04:21.060 --> 00:04:25.409
我々は、このの残りの部分で使用します

97
00:04:22.680 --> 00:04:26.889
もちろん、単一のトレーニング例があります

98
00:04:25.409 --> 00:04:34.120
ペアで表さ

99
00:04:26.889 --> 00:04:37.749
Xは次元N XであるXコンマY

100
00:04:34.120 --> 00:04:41.310
特徴ベクトルとYラベルのいずれかであります

101
00:04:37.749 --> 00:04:45.219
0または1あなたのトレーニングセットが含むことになります

102
00:04:41.310 --> 00:04:47.830
小文字のMの訓練例など

103
00:04:45.219 --> 00:04:50.800
あなたのトレーニングセットは、X1に書き込まれます

104
00:04:47.830 --> 00:04:54.099
入力と出力されるコンマY1

105
00:04:50.800 --> 00:04:57.669
あなたの最初のトレーニングの例×2カンマ

106
00:04:54.099 --> 00:05:01.090
Xまでの第2のトレーニング例えばY2

107
00:04:57.669 --> 00:05:04.029
最後のトレーニングであるMのコンマY M

108
00:05:01.090 --> 00:05:06.250
例とその完全にこの

109
00:05:04.029 --> 00:05:08.860
私はするつもりだし、あなたの全体のトレーニング

110
00:05:06.250 --> 00:05:11.199
の数を示すために小文字Mを使用

111
00:05:08.860 --> 00:05:12.729
訓練例時にはへ

112
00:05:11.199 --> 00:05:14.529
これは数であることを強調

113
00:05:12.729 --> 00:05:16.779
訓練例は、私がこれを書くかもしれません

114
00:05:14.529 --> 00:05:19.719
Mの添字列車と我々はについて話すとき

115
00:05:16.779 --> 00:05:22.479
私たちは時々Mを使用することがありますテストセット

116
00:05:19.719 --> 00:05:25.029
の数を示すために添字試験

117
00:05:22.479 --> 00:05:29.650
そのためには、多数の試験例をです

118
00:05:25.029 --> 00:05:32.139
試験例では、最終的にすべてを置くために

119
00:05:29.650 --> 00:05:34.740
よりコンパクトに訓練例

120
00:05:32.139 --> 00:05:39.009
私たちが行列を定義するつもり表記

121
00:05:34.740 --> 00:05:42.639
資本Xあなたを取ることによって定義されています

122
00:05:39.009 --> 00:05:45.279
ようにトレーニングセット入力×1×2とし、

123
00:05:42.639 --> 00:05:48.759
あなたが取るので、もし列にそれらを積み重ねます

124
00:05:45.279 --> 00:05:52.060
x1と、あなたは最初の列としてそれを置きます

125
00:05:48.759 --> 00:05:55.719
cordettaこのマトリックスとx2の

126
00:05:52.060 --> 00:05:58.899
第二カラムなど次いでX Mにダウン

127
00:05:55.719 --> 00:06:03.250
これは、このように、行列資本Xであります

128
00:05:58.899 --> 00:06:05.979
行列Xは、mはM列を有しています

129
00:06:03.250 --> 00:06:07.569
訓練例の数と、

130
00:06:05.979 --> 00:06:11.620
行数や、この高さ

131
00:06:07.569 --> 00:06:14.319
マトリックスは、他の原因であることNX通知であります

132
00:06:11.620 --> 00:06:16.509
あなたは行列資本Xが表示される場合があります

133
00:06:14.319 --> 00:06:19.979
訓練を積み重ねることによって定義されます

134
00:06:16.509 --> 00:06:24.789
そうX 1転置等行の例

135
00:06:19.979 --> 00:06:26.229
XのMの転置までそれが判明

136
00:06:24.789 --> 00:06:28.750
あなたは、神経を実装しようとしているときに

137
00:06:26.229 --> 00:06:30.219
私が持っている、この規則を使用してネットワーク

138
00:06:28.750 --> 00:06:35.409
左は、実装を行います

139
00:06:30.219 --> 00:06:39.699
はるかに簡単にこれだけXはn Xでおさらいします

140
00:06:35.409 --> 00:06:40.360
M次元の行列によるとしたとき

141
00:06:39.699 --> 00:06:44.080
これを補完します

142
00:06:40.360 --> 00:06:46.180
ピサンは、あなたはその元PARTEの形状を見ること

143
00:06:44.080 --> 00:06:50.080
形状を見つけるためのPythonコマンド

144
00:06:46.180 --> 00:06:52.210
これはMとXカンマであるマトリックスの

145
00:06:50.080 --> 00:06:54.460
これはちょうど意味MはMでNXであります

146
00:06:52.210 --> 00:06:57.460
次元マトリックスどのようにそれはですので、

147
00:06:54.460 --> 00:07:01.300
グループトレーニング例の入力Xに

148
00:06:57.460 --> 00:07:02.889
どのように出力ラベルYのそれについての行列

149
00:07:01.300 --> 00:07:04.449
あなたを作ることが判明

150
00:07:02.889 --> 00:07:08.110
ニューラルネットワークの実装

151
00:07:04.449 --> 00:07:10.659
簡単に私はYのスタックも便利になるだろう

152
00:07:08.110 --> 00:07:17.050
列に私たちは定義しようとしています

153
00:07:10.659 --> 00:07:22.979
YまでのY 1、Y 2に等しくなるように資本Y

154
00:07:17.050 --> 00:07:26.080
そのので、ここでYは、Mによって1になるようなM

155
00:07:22.979 --> 00:07:28.750
使用するために再び次元マトリックスと

156
00:07:26.080 --> 00:07:32.199
あなたはYの形を知っているPythonの表記

157
00:07:28.750 --> 00:07:35.740
ちょうどこのことを意味1コンマMになります

158
00:07:32.199 --> 00:07:37.810
M行列によると、実装として1であります

159
00:07:35.740 --> 00:07:40.330
このコースでは、後に自分のニューラルネットワーク

160
00:07:37.810 --> 00:07:42.759
便利な大会になるでしょう見つけます

161
00:07:40.330 --> 00:07:44.979
へのデータの関連付けを取ること

162
00:07:42.759 --> 00:07:47.379
異なるトレーニング例およびデータIによって

163
00:07:44.979 --> 00:07:49.839
X又はY又は他の量のいずれかを意味

164
00:07:47.379 --> 00:07:51.729
後で見るが、ものを取りますか、

165
00:07:49.839 --> 00:07:53.740
異なる関連付けられたデータ

166
00:07:51.729 --> 00:07:55.779
訓練例およびそれらを積み重ねます

167
00:07:53.740 --> 00:07:59.440
我々はここでやったように別の列

168
00:07:55.779 --> 00:08:01.509
xとyの両方のために、それは表記ですので

169
00:07:59.440 --> 00:08:03.310
我々は、ロジスティック回帰分析のために使用しますと、

170
00:08:01.509 --> 00:08:05.319
後でこのコースでは、ニューラルネットワークについて

171
00:08:03.310 --> 00:08:07.960
あなたは今までのどのような部分を忘れた場合

172
00:08:05.319 --> 00:08:10.120
表記はMまたは1がNであるもののような手段

173
00:08:07.960 --> 00:08:11.229
または他の1か何か我々も掲載しました

174
00:08:10.120 --> 00:08:13.479
コースのウェブサイト上

175
00:08:11.229 --> 00:08:15.159
表記法ガイドにあなたはすぐに使用することができます

176
00:08:13.479 --> 00:08:18.520
あなたが任意の特定のを知っていることを調べます

177
00:08:15.159 --> 00:08:20.259
それは行くことができますので、表記の部分を意味します

178
00:08:18.520 --> 00:08:22.539
次の動画へに我々はに始めましょう

179
00:08:20.259 --> 00:08:24.750
これを使用してロジスティック回帰を肉付け

180
00:08:22.539 --> 00:08:24.750
表記法
