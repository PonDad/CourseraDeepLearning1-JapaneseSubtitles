WEBVTT

1
00:00:00.340 --> 00:00:03.150
深い学習という用語は、
ニューラルネットワークをトレーニングする。

2
00:00:03.150 --> 00:00:05.340
時には非常に大きなニューラルネットワーク。

3
00:00:05.340 --> 00:00:07.700
だから正確にニューラルネットワークは何ですか？

4
00:00:07.700 --> 00:00:11.470
このビデオでは、
あなたには基本的な直感のいくつかがあります。

5
00:00:11.470 --> 00:00:15.300
住宅から始めましょう
価格予測の例。

6
00:00:15.300 --> 00:00:17.900
データがあるとしましょう
6つの家があります。

7
00:00:17.900 --> 00:00:20.700
だからあなたは
平方フィートまたは

8
00:00:20.700 --> 00:00:24.350
平方メートル、あなたは価格を知っている
家の中で、あなたはフィットしたい

9
00:00:24.350 --> 00:00:28.000
価格を予測する関数
サイズの関数としての家。

10
00:00:28.000 --> 00:00:31.600
あなたが線形に精通しているなら
あなたは、

11
00:00:31.600 --> 00:00:33.510
このデータに直線を当てはめましょう。

12
00:00:33.510 --> 00:00:36.880
だから多分あなたは持っている
そのような直線。

13
00:00:36.880 --> 00:00:38.850
しかし、少し好きであるためには、
あなたは言うかもしれません、まあ、

14
00:00:38.850 --> 00:00:42.170
価格は決してマイナスになることはありません。

15
00:00:42.170 --> 00:00:46.470
そのため、直線フィットの代わりに
最終的には否定的になり、

16
00:00:46.470 --> 00:00:49.930
ここでカーブを曲げましょう
ここではゼロに終わるだけです。

17
00:00:49.930 --> 00:00:55.060
この太い青い線が終わる
あなたの機能として

18
00:00:55.060 --> 00:00:58.150
家の価格を予測する
その大きさに応じて変化する。

19
00:00:58.150 --> 00:01:02.040
一方、ここではゼロとし、次に
直線は右側に収まる。

20
00:01:02.040 --> 00:01:06.180
この機能は、
あなたはちょうど住宅価格に合っている

21
00:01:06.180 --> 00:01:08.490
非常に単純なニューロネットワークです。

22
00:01:08.490 --> 00:01:10.870
それはほぼ一番簡単です
可能なニューロネットワーク。

23
00:01:10.870 --> 00:01:11.620
ここに描こう。

24
00:01:13.800 --> 00:01:17.200
我々はニューロ・ネットワークへの入力として、
家の大きさ、

25
00:01:17.200 --> 00:01:18.800
これをxと呼ぶ。

26
00:01:18.800 --> 00:01:22.480
それはこのノードに入り、
この小さな円。

27
00:01:23.930 --> 00:01:27.450
そして、yと呼ばれる価格を出力します。

28
00:01:28.470 --> 00:01:33.830
だからこの小さなサークル
単一のニューロンであり、

29
00:01:33.830 --> 00:01:39.380
あなたのネットワークはこれを実装します
私たちが左に描いた機能です。

30
00:01:39.380 --> 00:01:43.630
そして、ニューロネットの文献では、
あなたはこの機能をたくさん見ています。

31
00:01:43.630 --> 00:01:48.530
いつかゼロになるこの関数
直線として外れる。

32
00:01:48.530 --> 00:01:53.156
この機能は、ReLU

33
00:01:53.156 --> 00:01:57.597
関数

34
00:01:57.597 --> 00:02:03.080
整流されたリニアユニットですので、ReLU。

35
00:02:03.080 --> 00:02:05.330
そして単に手段を是正する
最大値0をとると、

36
00:02:05.330 --> 00:02:07.900
それがあなたが得る理由です
このような形の関数。

37
00:02:07.900 --> 00:02:10.790
あなたは心配する必要はありません
ReLUユニットは今のところ

38
00:02:10.790 --> 00:02:13.580
それはあなたが見るものです
このコースの後半にもう一度。

39
00:02:13.580 --> 00:02:17.130
したがって、これが単一のニューラルネットワークである場合、

40
00:02:17.130 --> 00:02:22.330
多分小さな小さな神経回路網、
より大きなニューラルネットワーク

41
00:02:22.330 --> 00:02:27.980
これらの多くを取ることによって形成される
単一のニューロンとそれらを積み重ねる。

42
00:02:27.980 --> 00:02:34.190
あなたがこのニューロンを考えているなら、
単一のレゴレンガのように、あなたは

43
00:02:34.190 --> 00:02:38.740
積み重ねてより大きなニューラルネットワークを得る
これらのレゴレンガの多くを一緒に。

44
00:02:38.740 --> 00:02:39.980
例を見てみましょう。

45
00:02:39.980 --> 00:02:44.830
予測する代わりに
ちょうどそのサイズから家の価格、

46
00:02:44.830 --> 00:02:49.060
あなたは今他の機能を持っています。
家に関する他のこと、

47
00:02:49.060 --> 00:02:53.690
ベッドルームの数、
私たちはこの[不可能な]寝室を書いてください。

48
00:02:53.690 --> 00:02:57.760
そして、あなたは、
本当に影響を与えること

49
00:02:57.760 --> 00:03:00.885
家の価格は家族の大きさです。

50
00:03:00.885 --> 00:03:06.010
それでこの家はあなたの3人家族に合っていますか
または4人の家族、または5人の家族？

51
00:03:06.010 --> 00:03:10.022
それは実際には
平方フィートまたは平方メートル、および

52
00:03:10.022 --> 00:03:12.878
寝室の数
それが

53
00:03:12.878 --> 00:03:15.608
家があなたに合っていない
家族の家族のサイズ。

54
00:03:15.608 --> 00:03:20.047
そして、あなたが知っているかもしれない
異なる郵便番号

55
00:03:20.047 --> 00:03:24.518
国を郵便番号と呼びます。

56
00:03:24.518 --> 00:03:30.660
そして、郵便番号は、おそらく機能として
それはあなたに歩行性を教えてくれます。

57
00:03:30.660 --> 00:03:33.940
それでこの近所は非常にウォークスルーです

58
00:03:33.940 --> 00:03:36.140
あなたは食料品店に歩いて行くことができますか？
学校に行く？

59
00:03:36.140 --> 00:03:37.160
運転する必要がありますか？

60
00:03:37.160 --> 00:03:39.880
一部の人々は高く好む
歩くことができる近所。

61
00:03:39.880 --> 00:03:45.156
そして、郵便番号、
多分、富はおそらく、

62
00:03:45.156 --> 00:03:49.840
確かに、米国ではあなたに言います。

63
00:03:49.840 --> 00:03:55.290
しかし、他の国々も同様に
学校の質はどれくらい良いですか。

64
00:03:55.290 --> 00:03:59.496
だから私はこれらの小さなサークルのそれぞれ
描画は、それらのReLUの1つにすることができます、

65
00:03:59.496 --> 00:04:04.428
整流された線形ユニット、またはその他のもの
わずかに非線形関数なので、

66
00:04:04.428 --> 00:04:08.721
寝室のサイズと数については、
あなたは家族のサイズを見積もることができます。

67
00:04:08.721 --> 00:04:10.483
郵便番号を使用して、歩行性を推定し、

68
00:04:10.483 --> 00:04:12.970
あなたにも郵便番号に基づいて
学校の質を見積もることができます。

69
00:04:12.970 --> 00:04:15.202
そして最後に、あなたは、

70
00:04:15.202 --> 00:04:18.030
よく、人々がどのように決定するか
彼らは喜んで支払っている

71
00:04:18.030 --> 00:04:20.610
家は物を見ている
それは本当に彼らにとって重要です。

72
00:04:20.610 --> 00:04:24.780
この場合、家族のサイズ、
歩行性と学校の質

73
00:04:24.780 --> 00:04:27.190
それはあなたが価格を予測するのに役立ちます。

74
00:04:27.190 --> 00:04:31.930
したがって、この例では、xはこれら4つのすべてです

75
00:04:31.930 --> 00:04:38.010
入力と
yは予測しようとしている価格です。

76
00:04:38.010 --> 00:04:43.350
それで、
単一のニューロンまたは単純な予測子

77
00:04:43.350 --> 00:04:46.850
私たちは以前のスライドから
わずかに大きなニューロネットワークを持っています。

78
00:04:46.850 --> 00:04:51.790
それは、多くの
神経回路網は私が

79
00:04:51.790 --> 00:04:56.650
必要に応じてニューロネットワークを説明しました
あなたは家族のサイズを把握するために、

80
00:04:56.650 --> 00:04:59.880
歩行性および
学校の質が要因である、または

81
00:04:59.880 --> 00:05:01.660
価格を決定するもの

82
00:05:01.660 --> 00:05:05.260
ニューラルネットワークの魔法の一部
あなたがそれを実装するとき、

83
00:05:05.260 --> 00:05:08.540
入力xだけを与える必要があります。

84
00:05:10.160 --> 00:05:14.340
そして、出力yは、
あなたのトレーニングセットの例

85
00:05:14.340 --> 00:05:17.370
真ん中のこれらすべてのもの
それはそれだけで理解するでしょう。

86
00:05:17.370 --> 00:05:21.510
あなたが実際に実装しているのはこれです。

87
00:05:21.510 --> 00:05:24.208
ここであなたは神経を持っています
4つの入力を持つネットワーク

88
00:05:24.208 --> 00:05:27.760
したがって、フィーチャが入力する可能性があります
寝室のサイズの数である、

89
00:05:27.760 --> 00:05:31.990
郵便番号または郵便番号、および
近隣の富。

90
00:05:33.580 --> 00:05:38.140
そして、これらの入力機能を考えると、

91
00:05:38.140 --> 00:05:42.470
ニューラルネットワークの仕事
価格を予測することになります。

92
00:05:42.470 --> 00:05:47.726
また、これらの
サークル、これらは隠れユニットと呼ばれます

93
00:05:47.726 --> 00:05:53.342
ニューラルネットワークにおいて、それらの各々
4つの入力機能を入力します。

94
00:05:53.342 --> 00:05:57.939
例えば、これを言うよりむしろ
最初のノードは家族のサイズを表し、

95
00:05:57.939 --> 00:06:02.741
家族のサイズは機能にのみ依存します
x1とx2の代わりに、

96
00:06:02.741 --> 00:06:06.856
よく、ニューラルネットワーク、あなたが決める
あなたがこのノードを望むものは何でも

97
00:06:06.856 --> 00:06:10.990
4つの入力機能すべてを提供します
あなたが望むものを計算する。

98
00:06:10.990 --> 00:06:15.330
だから我々は層
この入力層です

99
00:06:15.330 --> 00:06:18.160
この層は中央にあり、
ニューラルネットワークは密接に接続されている

100
00:06:18.160 --> 00:06:22.610
すべての入力機能が
これらのサークルの誰もが真ん中にいる。

101
00:06:22.610 --> 00:06:27.860
そして、神経に関する注目すべきこと
ネットワークは、xに関する十分なデータが与えられている

102
00:06:27.860 --> 00:06:31.920
十分な訓練の例があればy
xとyの両方で、ニューラルネットワーク

103
00:06:31.920 --> 00:06:36.120
はっきり分かる
xからyに正確にマップする関数。

104
00:06:36.120 --> 00:06:38.886
それが基本的なニューラルネットワークです。

105
00:06:38.886 --> 00:06:42.320
それはあなたが
あなた自身の神経回路網はおそらくそれらを見つける

106
00:06:42.320 --> 00:06:46.130
最も有用な、最も強力な、
監督された学習設定で

107
00:06:46.130 --> 00:06:48.820
あなたが試みている意味
入力xと

108
00:06:48.820 --> 00:06:54.180
ちょうど見たように出力yをマップします
住宅価格予測の例では、

109
00:06:54.180 --> 00:06:58.070
次のビデオでは、
教師あり学習の例

110
00:06:58.070 --> 00:07:03.400
あなたがどこにいるのかの例
信じられないほど役に立つネットワーク

111
00:07:03.400 --> 00:07:04.039
あなたのアプリケーションも同様です。
