WEBVTT

1
00:00:00.060 --> 00:00:04.380
最後のビデオでは、我々は何ですかそらします

2
00:00:02.250 --> 00:00:06.150
深いリットル・ラリーのニューラルネットワークとも

3
00:00:04.380 --> 00:00:08.550
我々が使う表記法について話しました

4
00:00:06.150 --> 00:00:10.650
このビデオでは、このようなネットワークを記述します

5
00:00:08.550 --> 00:00:13.769
あなたが繁殖のために実行する方法を見て

6
00:00:10.650 --> 00:00:16.440
通常のletの最初の深ネットワークで

7
00:00:13.769 --> 00:00:18.660
何前方伝播の上に移動します

8
00:00:16.440 --> 00:00:21.330
単一のトレーニング例えばのように見えます

9
00:00:18.660 --> 00:00:22.920
Xおよびその後に、我々はについて話しましょう

10
00:00:21.330 --> 00:00:24.810
あなたがしたいベクトル化バージョン

11
00:00:22.920 --> 00:00:26.849
上前方伝播を実施

12
00:00:24.810 --> 00:00:29.660
同時に全体のトレーニングセットが、

13
00:00:26.849 --> 00:00:32.579
いくつかは、単一のトレーニング例Xを与えられました

14
00:00:29.660 --> 00:00:34.800
ここでは、アクティベーションを計算する方法です

15
00:00:32.579 --> 00:00:42.329
この第一のためにその第一層の

16
00:00:34.800 --> 00:00:48.239
あなたがZ1を計算する層は、W 1回Xに等しいです

17
00:00:42.329 --> 00:00:51.120
プラスB1ようなパラメータの1 W及びB

18
00:00:48.239 --> 00:00:53.879
それは、レイヤ1でのアクティベーションに影響を与えます

19
00:00:51.120 --> 00:00:56.899
右これは以下のいずれかがある場合

20
00:00:53.879 --> 00:00:59.280
ニューラルネットワークとあなたが計算

21
00:00:56.899 --> 00:01:04.979
等しくなるように、その層のためのアクティベーション

22
00:00:59.280 --> 00:01:06.810
Z 1のG及び宛先関数に

23
00:01:04.979 --> 00:01:09.090
Gは、あなたがにいる何層に依存し、

24
00:01:06.810 --> 00:01:11.010
多分インデックスABは、アクティベーションを持っています

25
00:01:09.090 --> 00:01:12.689
そこに1あなたがそれを行うので、場合の機能

26
00:01:11.010 --> 00:01:13.320
あなたは今からアクティベーションを計算しました

27
00:01:12.689 --> 00:01:18.360
レイヤー1

28
00:01:13.320 --> 00:01:24.470
どの層についても、その層を避けます

29
00:01:18.360 --> 00:01:32.189
あなたはその後、Z 2は、W 2 Aに等しい計算します

30
00:01:24.470 --> 00:01:34.950
1件のプラスB 2及びその後の活性化は、それほど

31
00:01:32.189 --> 00:01:39.180
レイヤ2は、マトリックス倍方法です

32
00:01:34.950 --> 00:01:44.270
層1の出力は、その結果の値であるプラス

33
00:01:39.180 --> 00:01:49.579
層2、次いでA2のバイアスベクトル

34
00:01:44.270 --> 00:01:55.770
活性化関数を適用等しいです

35
00:01:49.579 --> 00:01:57.990
Z2は大丈夫そう、それはようにレイヤ2とは終わりです

36
00:01:55.770 --> 00:02:00.299
など、あなたが出力されるまで

37
00:01:57.990 --> 00:02:06.240
あなたが希望4レイヤーの層

38
00:02:00.299 --> 00:02:09.959
Z 4は、パラメータと同じであることを持っています

39
00:02:06.240 --> 00:02:11.780
その層の回アクティベーションのために

40
00:02:09.959 --> 00:02:14.569
前の層から

41
00:02:11.780 --> 00:02:23.930
プラス、このベクターによる、その後、

42
00:02:14.569 --> 00:02:26.720
同様に4つV4などのGに等しいです

43
00:02:23.930 --> 00:02:29.900
それはあなたがあなたの推定を計算する方法です

44
00:02:26.720 --> 00:02:35.390
出力Yハット注意すので、ちょうど一つのこと

45
00:02:29.900 --> 00:02:38.270
Xここにも理由はゼロに等しいです

46
00:02:35.390 --> 00:02:41.209
入力特徴ベクトルXもあります

47
00:02:38.270 --> 00:02:44.000
レイヤー0のアクティベーションは、私たちはスクラッチアウト

48
00:02:41.209 --> 00:02:47.000
XとXのためのクロスとし、0を入れて

49
00:02:44.000 --> 00:02:48.709
ここで、あなたはこれらのすべてを知っています

50
00:02:47.000 --> 00:02:53.980
彼らは同じ権利を見て見方程式

51
00:02:48.709 --> 00:03:02.750
一般的なルールは、VLに等しいということです

52
00:02:53.980 --> 00:03:05.750
そこWL時間Lマイナス1プラスBのL 1

53
00:03:02.750 --> 00:03:10.630
その層そうしてからアクティベーション

54
00:03:05.750 --> 00:03:16.850
活性化関数は、に適用されます

55
00:03:10.630 --> 00:03:20.120
値Zそれはのための一般的ですので、

56
00:03:16.850 --> 00:03:23.540
伝播方程式ので、我々はすべてやりました

57
00:03:20.120 --> 00:03:26.299
この方法を単一のトレーニング例えば

58
00:03:23.540 --> 00:03:29.660
ベクトル化方法でそれを行うためについて

59
00:03:26.299 --> 00:03:32.720
同じに設定され、全​​体の訓練のために

60
00:03:29.660 --> 00:03:35.030
式はと全く同じように見える時間

61
00:03:32.720 --> 00:03:40.060
第一層のためには、事前に希望

62
00:03:35.030 --> 00:03:48.410
資本Z 1は、W 1回に等しく持っています

63
00:03:40.060 --> 00:03:54.650
資本XプラスB 1、次に1がGに等しいです

64
00:03:48.410 --> 00:03:57.920
心の中でZ 1、右と軸受のX

65
00:03:54.650 --> 00:03:59.959
0これらは、ちょうどあなたが知っているに等しいです

66
00:03:57.920 --> 00:04:01.850
に積層トレーニング例

67
00:03:59.959 --> 00:04:05.450
あなたがこれを取ることができる別の列

68
00:04:01.850 --> 00:04:08.269
あなたは0を置くことができるので、私はXをスクラッチアウトしましょう

69
00:04:05.450 --> 00:04:08.720
そこに、その後、次の層のルックスので、

70
00:04:08.269 --> 00:04:16.720
同様の

71
00:04:08.720 --> 00:04:21.980
Z 2は、W 2 1プラスB 2及び2に等しいです

72
00:04:16.720 --> 00:04:24.530
Z 2のGに等しいです

73
00:04:21.980 --> 00:04:28.370
私たちはこれらのベクトルEまたはAを取っています

74
00:04:24.530 --> 00:04:29.810
などなど、このそれらを積み重ね

75
00:04:28.370 --> 00:04:34.310
最初のトレーニングのためのVベクトルであります

76
00:04:29.810 --> 00:04:37.310
第2のトレーニングのための例のVベクトル

77
00:04:34.310 --> 00:04:39.830
例えば、というようにダウンM列車へ

78
00:04:37.310 --> 00:04:43.700
例と列にこれらを積み重ねます

79
00:04:39.830 --> 00:04:47.390
この資本Zはすべての権利を呼び出し、

80
00:04:43.700 --> 00:04:50.000
同様に、単に資本としての資本Aについて

81
00:04:47.390 --> 00:04:52.040
Xすべてのトレーニング例はコラムです

82
00:04:50.000 --> 00:04:53.720
ベクトルは右と左に萌芽します

83
00:04:52.040 --> 00:04:59.450
再びあなたは結局、このプロセスの終了

84
00:04:53.720 --> 00:05:03.200
V4のGに等しいとYハットそう

85
00:04:59.450 --> 00:05:04.670
これはまた、4に等しく、それはです

86
00:05:03.200 --> 00:05:08.000
すべてのビューの訓練の予測

87
00:05:04.670 --> 00:05:09.980
例はこれだけ水平に積層されています

88
00:05:08.000 --> 00:05:12.590
私たちの表記をまとめるために、私はするつもりです

89
00:05:09.980 --> 00:05:17.720
私たちの表記ができますここでこれを修正します

90
00:05:12.590 --> 00:05:19.820
私たちはと小文字のZと交換します

91
00:05:17.720 --> 00:05:22.070
大文字の対応は、すでにあります

92
00:05:19.820 --> 00:05:23.810
資本Dのように見え、それができます

93
00:05:22.070 --> 00:05:25.790
あなたのベクトル化バージョン第四

94
00:05:23.810 --> 00:05:29.060
あなたが上で実行する義務

95
00:05:25.790 --> 00:05:32.990
0時間での全トレーニングセット

96
00:05:29.060 --> 00:05:35.240
あなたはこれを見ている場合Xは今あります

97
00:05:32.990 --> 00:05:37.670
ベクトル化の実装は、それが見えます

98
00:05:35.240 --> 00:05:40.370
用があるように起こっていることのように

99
00:05:37.670 --> 00:05:44.360
ここでのループは、右のそれをLに残されています

100
00:05:40.370 --> 00:05:47.000
介して1に等しいL 4に1に等しいです

101
00:05:44.360 --> 00:05:48.950
資本Lあなたが計算しておく必要が

102
00:05:47.000 --> 00:05:51.860
層2、次いで層1のためのアクティベーション

103
00:05:48.950 --> 00:05:54.370
次いで、3層にし、したがって、その後4

104
00:05:51.860 --> 00:05:56.660
ここでは、forループがあるようですし、

105
00:05:54.370 --> 00:05:58.550
私はあなたを実装するときにことを知っています

106
00:05:56.660 --> 00:06:00.770
ネットワークは、我々は通常の解消を取得したいです

107
00:05:58.550 --> 00:06:03.290
ループの明示的なが、これは一つの場所であります

108
00:06:00.770 --> 00:06:05.060
私は考えていない場所にどのような方法があります

109
00:06:03.290 --> 00:06:06.590
明示以外の上でこれを実装

110
00:06:05.060 --> 00:06:09.080
ループのために私たちは、のために実装しています

111
00:06:06.590 --> 00:06:10.700
伝播持っていることは完全にOKです

112
00:06:09.080 --> 00:06:12.740
ループのために、彼らは、アクティベーションを計算します

113
00:06:10.700 --> 00:06:15.050
レイヤ1のために、その後2は、彼らはそこです

114
00:06:12.740 --> 00:06:17.210
スリーがあるので、誰もが知っています

115
00:06:15.050 --> 00:06:19.970
そして私は、これはどのような方法があるとは思いません

116
00:06:17.210 --> 00:06:23.060
行くループにせずにこれを行うには

117
00:06:19.970 --> 00:06:24.620
1から資本Lへの1から貫通

118
00:06:23.060 --> 00:06:27.830
層の、あなたの総数

119
00:06:24.620 --> 00:06:30.980
ネットワークので、この場所は完全に大丈夫です

120
00:06:27.830 --> 00:06:32.690
そう明示的なフォームを持っています

121
00:06:30.980 --> 00:06:35.300
それは深いの表記法のためにそれです

122
00:06:32.690 --> 00:06:37.760
ニューラルネットワークと同様のために行う方法として、

123
00:06:35.300 --> 00:06:39.680
もしこれらのネットワーク内での伝播

124
00:06:37.760 --> 00:06:41.900
我々はこれまで見てきた作品が少し見えます

125
00:06:39.680 --> 00:06:44.000
どのようなので、それはだあなたに少し馴染み

126
00:06:41.900 --> 00:06:45.830
我々は非常に作品を取って見てきました

127
00:06:44.000 --> 00:06:47.750
あなたが見てきたものに似て

128
00:06:45.830 --> 00:06:50.750
隠されたシングルとニューラルネットワーク

129
00:06:47.750 --> 00:06:53.420
層と、ちょうどその回以上の繰り返し

130
00:06:50.750 --> 00:06:55.420
今、私たちは深く実施していることが判明しました

131
00:06:53.420 --> 00:06:57.860
ニューラルネットワークへのいずれかの方法

132
00:06:55.420 --> 00:06:59.450
無料の上に持っていることのあなたの確率を高めます

133
00:06:57.860 --> 00:07:01.580
実装は非常に考えることです

134
00:06:59.450 --> 00:07:03.500
体系的かつ慎重について

135
00:07:01.580 --> 00:07:05.300
あなたがそうで作業している行列の次元

136
00:07:03.500 --> 00:07:07.280
私は自分のコードIを開発しようとしているとき

137
00:07:05.300 --> 00:07:08.960
多くの場合、一枚の紙を引っ張るだけ

138
00:07:07.280 --> 00:07:11.480
そうを通じて慎重に考えます

139
00:07:08.960 --> 00:07:13.940
私が働いている行列の次元

140
00:07:11.480 --> 00:07:16.570
のは、あなたがそれを行うことができる方法を見てみましょうと

141
00:07:13.940 --> 00:07:16.570
次のビデオ