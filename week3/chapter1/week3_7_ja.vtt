WEBVTT

1
00:00:00.030 --> 00:00:04.710
なぜあなたの新しいネットワークは必要ありません

2
00:00:02.220 --> 00:00:06.089
非線形活性化関数が判明します

3
00:00:04.710 --> 00:00:08.160
計算する新しいネットワークのためのもの

4
00:00:06.089 --> 00:00:09.990
あなたがする必要がありますか興味深い機能

5
00:00:08.160 --> 00:00:12.990
非線形活性化関数を取ります

6
00:00:09.990 --> 00:00:15.990
あまりあなただけの小道具のためにそうしたいです

7
00:00:12.990 --> 00:00:18.029
ニューラルネットワーク理由のための方程式

8
00:00:15.990 --> 00:00:22.160
私達はちょうど取り払うこの取り除くません

9
00:00:18.029 --> 00:00:25.920
関数Gと設定a1は等しいZ 1又は

10
00:00:22.160 --> 00:00:28.289
代わりに、あなたはZのGを言うことができます

11
00:00:25.920 --> 00:00:31.470
右時々これがZに等しいです。

12
00:00:28.289 --> 00:00:33.210
線形活性化関数と呼ばれます

13
00:00:31.470 --> 00:00:35.280
多分それのためのより良い名前は次のようになります

14
00:00:33.210 --> 00:00:37.280
アイデンティティ活性化機能なぜなら

15
00:00:35.280 --> 00:00:39.270
彼らは、入力されたものは何でもちょうど出力しています

16
00:00:37.280 --> 00:00:44.010
この目的のために

17
00:00:39.270 --> 00:00:46.410
何a2はZ2ためにちょうど同じだった場合、それはターン

18
00:00:44.010 --> 00:00:50.730
あなたがこれを行う場合は、このモデルがあるアウト

19
00:00:46.410 --> 00:00:54.390
ただ、線形としてYまたはYの帽子を計算します

20
00:00:50.730 --> 00:00:57.170
ご入力の機能は、X2テイクています

21
00:00:54.390 --> 00:01:05.970
あなたがいることを持っている場合は、最初の二つの式

22
00:00:57.170 --> 00:01:12.720
a1がZ1と等しいW1のXに等しいプラス

23
00:01:05.970 --> 00:01:21.869
Bと等しいa2はZ2に等しい場合、次いで

24
00:01:12.720 --> 00:01:24.900
あなたが取るならば、2つのA1プラスB W

25
00:01:21.869 --> 00:01:32.009
A1の定義とそこにそれを差し込みます

26
00:01:24.900 --> 00:01:38.520
あなたは、a2はW 2倍Wに等しいことを見つけます

27
00:01:32.009 --> 00:01:43.920
1 XプラスB1ビットのすべての権利ので、これはあります

28
00:01:38.520 --> 00:01:59.120
UM 1つのプラスB 2とこれが簡素化

29
00:01:43.920 --> 00:02:06.120
W 2 W 1 XプラスW 2、B1、B2、プラスので、これに

30
00:01:59.120 --> 00:02:08.930
それだけのは、このワットプライムBを呼び出してみましょう

31
00:02:06.120 --> 00:02:10.710
プライムそれはワットプライムXにちょうど等しくなるように

32
00:02:08.930 --> 00:02:12.720
プラスBプライム

33
00:02:10.710 --> 00:02:15.690
あなたは、線形活性化を使用した場合

34
00:02:12.720 --> 00:02:18.690
機能または私達はアイデンティティ、それらを呼び出すために行きます

35
00:02:15.690 --> 00:02:20.940
その後、新しいアクティベーション機能

36
00:02:18.690 --> 00:02:24.390
ネットワークは、単に線形を出力しています

37
00:02:20.940 --> 00:02:26.940
入力の機能と、私たちは話しましょう

38
00:02:24.390 --> 00:02:28.740
深いネットワークに関する以降の新しいネットワーク

39
00:02:26.940 --> 00:02:31.260
隠された多くの多くの多くの多くの層を持ちます

40
00:02:28.740 --> 00:02:33.570
層と、それはあなたが使用している場合ことが判明

41
00:02:31.260 --> 00:02:35.070
線形活性化関数または

42
00:02:33.570 --> 00:02:37.140
あなたは持っていない代わり場合

43
00:02:35.070 --> 00:02:38.790
活性化関数その後、どんなに

44
00:02:37.140 --> 00:02:41.610
あなたのニューラルネットワークが持っている多くの層

45
00:02:38.790 --> 00:02:43.590
常にちょうど線形を計算されてやって

46
00:02:41.610 --> 00:02:46.980
活性化関数あなたにも可能性がありますので、

47
00:02:43.590 --> 00:02:49.770
任意の隠れ層にのいくつかを持っていません

48
00:02:46.980 --> 00:02:52.020
簡単に回ってしまう言及した例

49
00:02:49.770 --> 00:02:54.510
あなたは線形活性化を持っている場合、そのアウト

50
00:02:52.020 --> 00:02:57.000
ここでは機能やシグモイド関数

51
00:02:54.510 --> 00:02:59.010
ここでは、このモデルはもうありません

52
00:02:57.000 --> 00:03:02.700
標準ロジスティックより表現力

53
00:02:59.010 --> 00:03:04.440
私は任意の隠れ層のない回帰

54
00:03:02.700 --> 00:03:06.360
これを証明するためにわざわざいますが、可能性はありません

55
00:03:04.440 --> 00:03:09.240
あなたがしたい場合は、そうしようとするが、

56
00:03:06.360 --> 00:03:12.690
手取りを線形が隠されていることである層

57
00:03:09.240 --> 00:03:15.000
多かれ少なかれ役に立たないためであります

58
00:03:12.690 --> 00:03:17.850
2つの線形関数の組成物であります

59
00:03:15.000 --> 00:03:20.190
自身線形関数ますない限り、

60
00:03:17.850 --> 00:03:21.989
そこに非直線性を投げます

61
00:03:20.190 --> 00:03:24.060
あなたはもっと面白い計算していません

62
00:03:21.989 --> 00:03:27.209
あなたがより深く行くにもとして機能

63
00:03:24.060 --> 00:03:28.739
ネットワークただ一つの場所場所があります

64
00:03:27.209 --> 00:03:32.820
あなたは、線形活性化を使用する場合があります

65
00:03:28.739 --> 00:03:35.640
Zの関数GはZに等しく、それがあればです

66
00:03:32.820 --> 00:03:38.790
あなたは上の機械学習を行っています

67
00:03:35.640 --> 00:03:41.130
回帰問題Yは本物であるかのように、

68
00:03:38.790 --> 00:03:44.640
数たとえば、あなたがしようとしているのであれば

69
00:03:41.130 --> 00:03:47.010
住宅価格を予測するので、Yはそれのです

70
00:03:44.640 --> 00:03:50.430
ない0 1それはあなたが知っている実数です

71
00:03:47.010 --> 00:03:53.340
ゼロドルからどこでもでの価格です

72
00:03:50.430 --> 00:03:55.650
しかし、高価な右まで穴

73
00:03:53.340 --> 00:03:58.530
親族の家私は多分しかし、ことができますね

74
00:03:55.650 --> 00:04:03.000
あなたは何百万人の潜在的に知っていること

75
00:03:58.530 --> 00:04:07.160
ドルそうしかし、しかし、多くの家屋

76
00:04:03.000 --> 00:04:11.670
Yが上取る場合、あなたのデータでコストが設定されていますが、

77
00:04:07.160 --> 00:04:13.829
これらの実際の値は、それはOKになるかもしれません

78
00:04:11.670 --> 00:04:19.380
ここでは、線形活性化関数を持っています

79
00:04:13.829 --> 00:04:21.060
あなたの出力Yの帽子も本物であるように、

80
00:04:19.380 --> 00:04:24.750
マイナスからどこにも数

81
00:04:21.060 --> 00:04:27.630
プラス無限大に無限大が、その後

82
00:04:24.750 --> 00:04:29.580
隠れユニットは、新たに使用すべきではありません

83
00:04:27.630 --> 00:04:33.180
彼らはreluを使用することができ、活性化機能

84
00:04:29.580 --> 00:04:35.370
または10Hまたはこれらのあなたはreluまたは多分

85
00:04:33.180 --> 00:04:37.020
一箇所ので何か他ます

86
00:04:35.370 --> 00:04:40.230
線形活性化関数を使用する場合があります

87
00:04:37.020 --> 00:04:43.350
通常、出力層の他人が、

88
00:04:40.230 --> 00:04:46.820
線形を使用した以外の

89
00:04:43.350 --> 00:04:48.690
フィッティング層における活性化関数

90
00:04:46.820 --> 00:04:51.540
いくつかの非常に特別を除きます

91
00:04:48.690 --> 00:04:53.640
圧縮に関連する状況

92
00:04:51.540 --> 00:04:55.200
それは使用して話をしたくはありません

93
00:04:53.640 --> 00:04:57.180
線形活性化関数は非常にあります

94
00:04:55.200 --> 00:04:59.100
ああ稀で、実際のコース今日

95
00:04:57.180 --> 00:05:01.230
あなたが見たように住宅価格を予測します

96
00:04:59.100 --> 00:05:03.450
住宅価格ので、週1ビデオ

97
00:05:01.230 --> 00:05:06.210
おそらく、すべて非負です

98
00:05:03.450 --> 00:05:09.180
あなたは価値の活性化機能を使用することができます

99
00:05:06.210 --> 00:05:12.030
ので、あなたの出力Yの帽子はすべてしていること

100
00:05:09.180 --> 00:05:14.040
私は願っています0以上

101
00:05:12.030 --> 00:05:16.170
それはあなたの理由を持っていることの感覚を与えます

102
00:05:14.040 --> 00:05:19.620
非線形活性化関数であります

103
00:05:16.170 --> 00:05:21.030
ニューラルネットワークの次の重要な部分

104
00:05:19.620 --> 00:05:24.330
我々は話を開始するつもりです

105
00:05:21.030 --> 00:05:25.950
設定するためにそれを行うために勾配降下し、

106
00:05:24.330 --> 00:05:28.320
勾配降下のための議論のためのアップ

107
00:05:25.950 --> 00:05:30.810
次のビデオでは、私はどのようにお見せしたいです

108
00:05:28.320 --> 00:05:33.150
の傾きを計算する方法を推定します

109
00:05:30.810 --> 00:05:35.070
個々の活性化誘導体

110
00:05:33.150 --> 00:05:37.430
機能は次のように進むましょう

111
00:05:35.070 --> 00:05:37.430
ビデオ
