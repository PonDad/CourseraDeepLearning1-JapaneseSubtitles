WEBVTT

1
00:00:00.000 --> 00:00:03.840
すべての権利、私はのはエキサイティングなことだと思います

2
00:00:01.800 --> 00:00:06.240
このビデオでは動画あなたはどのように見

3
00:00:03.840 --> 00:00:08.730
あなたのために勾配降下を実装

4
00:00:06.240 --> 00:00:10.530
1つの隠れ層のあるニューラルネットワーク

5
00:00:08.730 --> 00:00:12.809
このビデオ私はあなたを与えるつもりです

6
00:00:10.530 --> 00:00:14.639
あなたが実装する必要が方程式

7
00:00:12.809 --> 00:00:17.039
の伝播を取り戻すために

8
00:00:14.639 --> 00:00:19.410
勾配降下で、その後の作業と

9
00:00:17.039 --> 00:00:21.510
私はいくつかのより多くを与えるでしょう。この1後の映像

10
00:00:19.410 --> 00:00:24.150
これらの特定の理由についての直観

11
00:00:21.510 --> 00:00:26.070
方程式は、正確な式ですか、

12
00:00:24.150 --> 00:00:27.630
コンピューティングのための正しい方程式

13
00:00:26.070 --> 00:00:28.289
あなたは、神経のために必要な勾配

14
00:00:27.630 --> 00:00:30.090
ネットワーク

15
00:00:28.289 --> 00:00:32.520
そのシングルを使用してニューラルネットワーク

16
00:00:30.090 --> 00:00:39.930
今の農民層を持っています

17
00:00:32.520 --> 00:00:44.760
W 2 1 V W 1及びB 2などのようなパラメータ

18
00:00:39.930 --> 00:00:50.399
あなたはNXの選択肢を持っている場合はリマインダー

19
00:00:44.760 --> 00:00:56.640
UM nは0入力機能とN 1が隠れ

20
00:00:50.399 --> 00:00:59.149
単位nは、当社における2つの出力ユニット

21
00:00:56.640 --> 00:01:05.670
例はこれまでまだn 2は1に等しくありません

22
00:00:59.149 --> 00:01:08.880
次いで、行列W 1は、nは0 VでN 1であろう

23
00:01:05.670 --> 00:01:11.250
図1は、そうN 1次元ベクトルになり

24
00:01:08.880 --> 00:01:13.350
あなたは1で10-1として書き留めることができます

25
00:01:11.250 --> 00:01:16.500
本当に次元マトリックスの列

26
00:01:13.350 --> 00:01:20.750
W 2のベクトルの次元は、N 2であろう

27
00:01:16.500 --> 00:01:26.759
N 1とBの寸法によって2あろう

28
00:01:20.750 --> 00:01:28.590
これまでのところ、我々は再びきた1つの右されることによりn 2

29
00:01:26.759 --> 00:01:30.930
nが2に等しい場合にのみ見られる例

30
00:01:28.590 --> 00:01:36.930
あなただけの1つの持っている1

31
00:01:30.930 --> 00:01:39.570
隠されたユニットは、あなたはまた、コストを持っているので、

32
00:01:36.930 --> 00:01:41.340
ニューラルネットワークのためとする機能

33
00:01:39.570 --> 00:01:44.220
今私はちょうどあなたがしていると仮定するつもりです

34
00:01:41.340 --> 00:01:48.659
そのためには、バイナリ分類を行っています

35
00:01:44.220 --> 00:01:51.740
あなたのパラメータのコストなどをケース

36
00:01:48.659 --> 00:01:57.090
次のは、mの上で1になるだろう

37
00:01:51.740 --> 00:01:59.969
その損失関数の平均値などL

38
00:01:57.090 --> 00:02:03.420
ここでの損失があるときに、あなたの新しいネットワーク

39
00:01:59.969 --> 00:02:06.240
Yの帽子は右、これは本当にAであると予測します

40
00:02:03.420 --> 00:02:07.649
2グランドが0でYに等しくなければなりません

41
00:02:06.240 --> 00:02:09.629
あなたがバイナリをやっている場合

42
00:02:07.649 --> 00:02:12.510
損失関数をすることができ分類

43
00:02:09.629 --> 00:02:15.030
正確にあなたがロジスティックのために使用するもの

44
00:02:12.510 --> 00:02:18.420
以前のようにパラメータを訓練するあなたの

45
00:02:15.030 --> 00:02:21.450
あなたはグラデーションを実行する必要があるアルゴリズム

46
00:02:18.420 --> 00:02:23.189
降下ニューラルネットワークを訓練するとき

47
00:02:21.450 --> 00:02:25.379
初期化することが重要です

48
00:02:23.189 --> 00:02:26.129
ランダムにすべてに丸めパラメータ

49
00:02:25.379 --> 00:02:28.140
ゼロ

50
00:02:26.129 --> 00:02:30.030
それが事実だ、なぜ私たちは、後に表示されますが、

51
00:02:28.140 --> 00:02:32.069
にパラメータを初期化した後

52
00:02:30.030 --> 00:02:34.140
何か勾配降下の各ループ

53
00:02:32.069 --> 00:02:36.780
予測を計算う

54
00:02:34.140 --> 00:02:42.359
あなたは基本的にあなたがyの帽子を知って計算します

55
00:02:36.780 --> 00:02:44.519
私のために私は1メートルを通じて、その後言うと等しいです

56
00:02:42.359 --> 00:02:49.440
あなたはとても導関数を計算する必要があります

57
00:02:44.519 --> 00:02:51.420
あなたはDW 1を計算する必要があり、それは我々です

58
00:02:49.440 --> 00:02:54.359
コスト関数の微分を見ます

59
00:02:51.420 --> 00:02:56.489
1あなたWパラメータに関して

60
00:02:54.359 --> 00:02:59.220
別の変数を計算する必要があります

61
00:02:56.489 --> 00:03:00.870
あるDP 1を呼び出すために起こっています

62
00:02:59.220 --> 00:03:04.109
誘導体またはあなたの費用のスロープ

63
00:03:00.870 --> 00:03:07.349
変数Bに対して機能

64
00:03:04.109 --> 00:03:10.170
他の1等と同様

65
00:03:07.349 --> 00:03:12.629
最後に、その後2及びB 2およびWパラメータ

66
00:03:10.170 --> 00:03:17.879
勾配降下更新がするだろう

67
00:03:12.629 --> 00:03:22.709
1つのマイナスアルファWとして更新W 1

68
00:03:17.879 --> 00:03:26.129
D W1のV 1が取得する学習率の倍

69
00:03:22.709 --> 00:03:31.620
B 1マイナス学習率のように更新

70
00:03:26.129 --> 00:03:34.739
時間D B 1と同様にW 2及びB 2

71
00:03:31.620 --> 00:03:36.299
そして時々私はコロンに等しいと使用

72
00:03:34.739 --> 00:03:38.489
時々、どちらかのどちらかと等しいです

73
00:03:36.299 --> 00:03:40.829
表記は正常に動作してので、これは次のようになります

74
00:03:38.489 --> 00:03:42.510
勾配降下の1回の繰り返しと

75
00:03:40.829 --> 00:03:44.280
その後、あなたの繰り返し、このいくつかの数

76
00:03:42.510 --> 00:03:46.079
あなたのパラメータになるまでの時間は次のようになり

77
00:03:44.280 --> 00:03:48.150
彼らは以前の動画でそう収束しています

78
00:03:46.079 --> 00:03:50.099
私たちはどのように計算するかについて話しました

79
00:03:48.150 --> 00:03:51.629
出力を計算するためにどのような予測

80
00:03:50.099 --> 00:03:54.060
そして、私たちは中にそれを行う方法を説明しました

81
00:03:51.629 --> 00:03:56.269
道にも鍵がにあるように、ベクトル化

82
00:03:54.060 --> 00:04:00.180
これらの部分を計算する方法を知っています

83
00:03:56.269 --> 00:04:04.079
誘導体という用語DW 1、DB 1、ならびに

84
00:04:00.180 --> 00:04:06.780
デリバティブBW 2及びDP 2としてだから何

85
00:04:04.079 --> 00:04:09.419
私はあなたを与えるされてやってみたいです

86
00:04:06.780 --> 00:04:12.150
計算するために必要な方程式

87
00:04:09.419 --> 00:04:14.699
これらのデリバティブと私はに延期ます

88
00:04:12.150 --> 00:04:17.430
にオプションのビデオで次のビデオ

89
00:04:14.699 --> 00:04:19.090
私たちが来たかについてジェフに大きなターンを行きます

90
00:04:17.430 --> 00:04:21.400
これらの式で最大

91
00:04:19.090 --> 00:04:26.169
そうしてもう一度まとめます

92
00:04:21.400 --> 00:04:33.250
あなたのその伝播のための方程式

93
00:04:26.169 --> 00:04:37.900
有するZ 1は、W 1 XプラスB 1とが等しいです

94
00:04:33.250 --> 00:04:41.680
1の活性化関数に等しく

95
00:04:37.900 --> 00:04:49.690
その層は、V以来Y以外の適用しました

96
00:04:41.680 --> 00:04:53.530
1、次いで、Z 2は、W 2 A 1プラスB 2に等しいです

97
00:04:49.690 --> 00:04:55.180
その後、最終的には違いすべて

98
00:04:53.530 --> 00:05:01.210
右のセットトレーニング全体でベクトル化

99
00:04:55.180 --> 00:05:02.740
2探してV 2のG 2であります

100
00:05:01.210 --> 00:05:04.870
今、私たちは、あなたがバイナリをやっていると仮定した場合

101
00:05:02.740 --> 00:05:06.610
分類し、この活性化

102
00:05:04.870 --> 00:05:08.560
機能は本当にシグモイドする必要があります

103
00:05:06.610 --> 00:05:11.080
関数は、私はちょうどここでそれを投げますよ

104
00:05:08.560 --> 00:05:13.870
そのためには、前方伝播やです

105
00:05:11.080 --> 00:05:15.729
左から右のための前方の計算

106
00:05:13.870 --> 00:05:18.430
あなたのニューラルネットワークの次のレッツ・コンピューティング

107
00:05:15.729 --> 00:05:24.750
これはバック誘導体であります

108
00:05:18.430 --> 00:05:30.750
伝播ステップは、それはDZ 2計算します

109
00:05:24.750 --> 00:05:33.610
2に等しいマイナスグランドトゥルースYと

110
00:05:30.750 --> 00:05:36.580
ただ単にメモとしてこのすべては、

111
00:05:33.610 --> 00:05:41.289
行列Yに例を横切ってベクトル化

112
00:05:36.580 --> 00:05:45.280
すべてのリストM行列によってこの合計1です

113
00:05:41.289 --> 00:05:51.370
あなたのMの例の水平それを

114
00:05:45.280 --> 00:05:55.330
判明DW 2は、実際にはこれと同じです

115
00:05:51.370 --> 00:05:58.870
ええとこれらの最初の3つの式は非常にあります

116
00:05:55.330 --> 00:06:00.900
物流のための勾配降下に類似

117
00:05:58.870 --> 00:06:00.900
回帰

118
00:06:00.960 --> 00:06:12.610
Xは、DIMMが等しいUM 1つのコンマに等しく維持されます

119
00:06:07.419 --> 00:06:15.580
真とほんの少しの詳細このNP

120
00:06:12.610 --> 00:06:18.070
ドットは、いくつかは、Pythonのnumpyのコマンドですか

121
00:06:15.580 --> 00:06:21.100
の一次元間で何か

122
00:06:18.070 --> 00:06:24.810
この場合の行列は、水平加算します

123
00:06:21.100 --> 00:06:27.600
そして、それは防ぎ何のqのDIMMあるん

124
00:06:24.810 --> 00:06:31.230
 - 面白いそれらのいずれかを出力するから、

125
00:06:27.600 --> 00:06:34.650
バンク1の寸法の種々の赤

126
00:06:31.230 --> 00:06:37.010
あなたは保つことによって、n個のカンマを知ってました

127
00:06:34.650 --> 00:06:41.280
彼らがこのことを保証し、真の続編

128
00:06:37.010 --> 00:06:44.580
Pythonはあるベクトルに4ギガバイトを出力します

129
00:06:41.280 --> 00:06:47.820
これがされる技術的に1を加算し、買います

130
00:06:44.580 --> 00:06:50.130
私は、この場合には1を購入するnは推測します

131
00:06:47.820 --> 00:06:53.520
ので、多分それを1つの番号でわずか1

132
00:06:50.130 --> 00:06:56.790
重要ではありませんが、後に、我々は表示されます

133
00:06:53.520 --> 00:06:58.500
それは本当に、これまで何を重要とき

134
00:06:56.790 --> 00:07:01.320
やった、私たちは物流と非常によく似ています

135
00:06:58.500 --> 00:07:03.919
回帰しかし、今あなたが計算して

136
00:07:01.320 --> 00:07:14.370
伝播にあなたを戻って実行し続けます

137
00:07:03.919 --> 00:07:19.380
このZ 2回G 1つの素数を計算することになります

138
00:07:14.370 --> 00:07:20.880
Z 1のように、この量G 1素数であります

139
00:07:19.380 --> 00:07:22.919
だった何の微分

140
00:07:20.880 --> 00:07:25.770
あなたが使用して活性化機能

141
00:07:22.919 --> 00:07:27.030
隠された層と出力層のためのI

142
00:07:25.770 --> 00:07:29.400
あなたがバイナリをやっていると仮定

143
00:07:27.030 --> 00:07:30.780
シグモイド関数と分類

144
00:07:29.400 --> 00:07:34.620
そのためには、すでにその中に焼いたのです

145
00:07:30.780 --> 00:07:39.090
DZ 2と、この回の計算式があります

146
00:07:34.620 --> 00:07:43.050
要素ごとの積ので、今年

147
00:07:39.090 --> 00:07:46.950
M行列でN 1があるように起こっています

148
00:07:43.050 --> 00:07:48.990
そしてここで、この、この要素が賢明

149
00:07:46.950 --> 00:07:52.680
派生事も可能になるだろう

150
00:07:48.990 --> 00:07:54.720
N行列とがので、この時間によってN 1

151
00:07:52.680 --> 00:07:59.669
2の他の分賢明な製品です

152
00:07:54.720 --> 00:08:08.490
行列は最終的にDW 1に等しいです

153
00:07:59.669 --> 00:08:18.950
それとDV 1本に等しく、Pドット

154
00:08:08.490 --> 00:08:21.900
1 Xは、いくつかのD Zは、1つのキープティムさんに等しいです。

155
00:08:18.950 --> 00:08:23.430
真等しいのに対しので、

156
00:08:21.900 --> 00:08:27.210
多分以前に安いビジネス

157
00:08:23.430 --> 00:08:28.590
問題以下n2は1000年ソファと等しい場合

158
00:08:27.210 --> 00:08:35.729
一つずつが本当ありますです

159
00:08:28.590 --> 00:08:38.370
ここ数P p1は1からnは1であろう

160
00:08:35.729 --> 00:08:40.110
ベクトルので、あなたがn個欲しいのPythonをしたいです

161
00:08:38.370 --> 00:08:43.110
Pは、このいくつかの出力に何かをドット

162
00:08:40.110 --> 00:08:46.529
大きさではなく、家族マチック1

163
00:08:43.110 --> 00:08:48.360
終わる可能性があり、その次元の配列

164
00:08:46.529 --> 00:08:50.580
アップあなたの後からのいくつかをめちゃくちゃ

165
00:08:48.360 --> 00:08:53.310
他の方法は、になります計算

166
00:08:50.580 --> 00:08:56.910
しかしにそれらにパラメータを維持する必要がありません

167
00:08:53.310 --> 00:09:00.060
明示的に再構築するためにリシェイプで呼び出します

168
00:08:56.910 --> 00:09:04.400
NPの出力は、この中にいくつかのドット

169
00:09:00.060 --> 00:09:08.310
あなたはので、どのようにDBを希望の寸法

170
00:09:04.400 --> 00:09:11.339
そのためには、私が推測するに、伝播のためでした

171
00:09:08.310 --> 00:09:14.310
Iにおける4つの方程式と逆伝播

172
00:09:11.339 --> 00:09:16.680
6つの方程式を推測私はちょうど書いた知っています

173
00:09:14.310 --> 00:09:18.870
これらの方程式ダウンが、次で

174
00:09:16.680 --> 00:09:22.050
オプションのビデオのいくつかの上に行きましょう

175
00:09:18.870 --> 00:09:23.940
以下のための方法を6つの方程式の直感

176
00:09:22.050 --> 00:09:25.830
バックプロパゲーションアルゴリズムました

177
00:09:23.940 --> 00:09:27.750
ことを見ていて自由にしてください導出

178
00:09:25.830 --> 00:09:30.000
かではないが、あなたが実装した場合のいずれかの方法

179
00:09:27.750 --> 00:09:32.730
これらのアルゴリズムは、正しいを持っています

180
00:09:30.000 --> 00:09:34.650
利益の背景用の実装

181
00:09:32.730 --> 00:09:36.750
あなたは計算することができます

182
00:09:34.650 --> 00:09:39.029
適用するために必要なデリバティブ

183
00:09:36.750 --> 00:09:41.520
パラメータを学ぶために勾配降下

184
00:09:39.029 --> 00:09:43.680
あなたのニューラルネットワークのそれはすることが可能です

185
00:09:41.520 --> 00:09:45.209
デザインルームを実装し、それが仕事に取り掛かります

186
00:09:43.680 --> 00:09:47.130
深く理解せず

187
00:09:45.209 --> 00:09:50.520
成功した人々の多くを計算

188
00:09:47.130 --> 00:09:52.320
収益実務家はそうしかし、あなたの場合

189
00:09:50.520 --> 00:09:54.180
あなたはまた、次のビデオを見ることができますしたいです

190
00:09:52.320 --> 00:09:56.580
ちょうど約もう少し直感を取得します

191
00:09:54.180 --> 00:09:58.820
これらのこれらの導出

192
00:09:56.580 --> 00:09:58.820
方程式