WEBVTT

1
00:00:00.000 --> 00:00:01.230
最後のビデオでは、

2
00:00:01.230 --> 00:00:03.720
あなたは、バックプロパゲーションのための方程式を見ました。

3
00:00:03.720 --> 00:00:06.900
このビデオでは、のは、使用して、いくつかの直感を超える手放します

4
00:00:06.900 --> 00:00:10.515
これらの方程式が導き出された方法のための計算グラフ。

5
00:00:10.515 --> 00:00:12.385
このビデオでは完全にオプションです。

6
00:00:12.385 --> 00:00:14.106
だから、見たりしないようにお気軽に。

7
00:00:14.106 --> 00:00:16.360
あなたは、全体の作業にいずれかの方法を行うことができるはず。

8
00:00:16.360 --> 00:00:19.410
我々はロジスティック回帰について話すときに、あることを思い出し、

9
00:00:19.410 --> 00:00:23.685
我々は、我々はZを計算し、このフォワード・パスを持っていました

10
00:00:23.685 --> 00:00:26.145
そして、その後、Aと損失。

11
00:00:26.145 --> 00:00:27.445
そして、デリバティブを取ります

12
00:00:27.445 --> 00:00:32.520
我々は、我々が最初にDAを計算することができ、この後方パスを持っていました

13
00:00:32.520 --> 00:00:35.400
その後、DZを計算するために行きます、

14
00:00:35.400 --> 00:00:40.720
その後、DWとDBを計算するために行きます。

15
00:00:40.720 --> 00:00:46.970
だから、損失の定義は、AのLでした

16
00:00:46.970 --> 00:00:52.655
Yは、マイナス1を記録し、負のYに等しいです。

17
00:00:52.655 --> 00:00:57.440
マイナスY回1つのマイナスA.を記録

18
00:00:57.440 --> 00:00:59.750
だから、あなたが精通している場合

19
00:00:59.750 --> 00:01:03.600
微積分、あなたがに関してこれの微分を取ります、

20
00:01:03.600 --> 00:01:06.156
それはあなたのDAための式を与えるだろう。

21
00:01:06.156 --> 00:01:09.060
だから、DAはそれと同じです。

22
00:01:09.060 --> 00:01:12.750
私たちが実際に微積分を見つけ出す場合、あなたはこれがあることを示すことができます

23
00:01:12.750 --> 00:01:18.808
負のY 1マイナスA.オーバープラス1つのマイナスYオーバー

24
00:01:18.808 --> 00:01:23.040
あなただけの種類の本の導関数を取ることによって、微積分からそれを分けます。

25
00:01:23.040 --> 00:01:26.680
あなたはDZを計算するために後方に別の一歩を踏み出すときには、判明します

26
00:01:26.680 --> 00:01:32.430
我々は、DZは、私は、なぜ以前に説明しなかったマイナスYに等しいことをうまくありませんでした

27
00:01:32.430 --> 00:01:37.920
それは計算のチャンバからDZが等しいことが判明します

28
00:01:37.920 --> 00:01:45.425
Z.のDA回Gプライムへ

29
00:01:45.425 --> 00:01:50.535
どこここでZのGは、Zのシグモイドに等しいです

30
00:01:50.535 --> 00:01:56.245
ロジスティック回帰分析では、この出力ユニットのための私達の活性化関数は、右ですか？

31
00:01:56.245 --> 00:02:00.570
だから、ただ、これはまだ我々はX1、X2を持つロジスティック回帰であることを覚えています

32
00:02:00.570 --> 00:02:05.757
X3その後、ちょうど1つのシグモイドユニットと、それが私たちに与え、

33
00:02:05.757 --> 00:02:07.400
意志が私たちにYの終了を示します。

34
00:02:07.400 --> 00:02:11.400
だから、ここ活性化関数はシグモイド関数であったされています。

35
00:02:11.400 --> 00:02:12.960
そして余談として、

36
00:02:12.960 --> 00:02:17.205
微積分のチャンバーに精通しているあなたのそれらのためにのみ

37
00:02:17.205 --> 00:02:22.520
この理由は、AはZのシグモイドに等しいので、

38
00:02:22.520 --> 00:02:29.310
そのため、Zに対するLの部分は、部分的に同一であります

39
00:02:29.310 --> 00:02:36.800
時間DA、DZに対してL。

40
00:02:36.800 --> 00:02:39.611
これは、AがZのシグモイドに等しいです

41
00:02:39.611 --> 00:02:42.970
これはDDZに等しく、

42
00:02:42.970 --> 00:02:49.080
Z.のG素数に等しいZのG

43
00:02:49.080 --> 00:02:54.060
DZは、我々のコードである。この式は等しいだから、なぜ、それはです

44
00:02:54.060 --> 00:02:59.484
Z.の我々のコードの回GプライムでDAであるこの式に

45
00:02:59.484 --> 00:03:05.860
そして、これはまさにそれです。

46
00:03:05.860 --> 00:03:09.172
だから、その最後の導出がいる場合にのみ意味を成しています

47
00:03:09.172 --> 00:03:13.510
あなたは計算と微積分からの特別室に精通しています。

48
00:03:13.510 --> 00:03:15.325
しかし、もしそれを心配しないでくださいではありません。

49
00:03:15.325 --> 00:03:18.853
私はそれが必要なのどこ直感を説明しようとするでしょう。

50
00:03:18.853 --> 00:03:22.315
そして最後に、この回帰のために計算されたDZを持ちます

51
00:03:22.315 --> 00:03:26.335
我々が判明したDWを計算しますました

52
00:03:26.335 --> 00:03:31.470
あなたは、単一のトレーニング例を持っているときだけDZあるDZ回XおよびDB。

53
00:03:31.470 --> 00:03:33.822
だから、それはロジスティック回帰でした。

54
00:03:33.822 --> 00:03:36.700
だから、私たちは戻って計算するときにやろうとしています

55
00:03:36.700 --> 00:03:40.090
ニューラルネットワークの伝播は、多くのように計算されます

56
00:03:40.090 --> 00:03:46.995
今、私たちは、出力部に行かないXしているため、これが唯一の私たちは、それを2回やります

57
00:03:46.995 --> 00:03:50.930
しかし、Xは、隠れ層に行くし、その後、出力部に行きます。

58
00:03:50.930 --> 00:03:58.405
そしてその代わりに、1つのステップのこの計算され、ソートの私たちは、ここに持っているように

59
00:03:58.405 --> 00:04:04.483
ここでは二つの層を持つニューラルネットワークのこの種では、あなたの2つのステップを持っています。

60
00:04:04.483 --> 00:04:08.586
そこで、我々は、入力層を持っているこの2層ニューラルネットワークでは、

61
00:04:08.586 --> 00:04:10.138
隠れ層と、出力層。

62
00:04:10.138 --> 00:04:12.070
計算の手順を覚えておいてください。

63
00:04:12.070 --> 00:04:17.210
まず、あなたはZ1は、この式を用いて計算し、

64
00:04:17.210 --> 00:04:22.177
その後、A1を計算し、その後、Z2を計算します。

65
00:04:22.177 --> 00:04:25.505
そしてZ2はまた、W2とB2のパラメータに依存気づきます。

66
00:04:25.505 --> 00:04:27.530
そして、Z2に基づいて、

67
00:04:27.530 --> 00:04:32.815
A2を計算し、最終的にそれはあなたに損失を与えます。

68
00:04:32.815 --> 00:04:41.560
どのようなバックプロパゲーション、それはその後、DA2とDZ2を計算するために後方に行くされず、

69
00:04:41.560 --> 00:04:48.805
その後、あなたがDW2とDP2を計算するために戻って、

70
00:04:48.805 --> 00:04:53.232
DA1を計算するために後方に移動し、

71
00:04:53.232 --> 00:04:57.278
DZ1のように。

72
00:04:57.278 --> 00:05:00.290
私たちはに関しとしてリベッターを取る必要はありません。

73
00:05:00.290 --> 00:05:03.745
教師あり学習サフィックスの入力X以降の入力X。

74
00:05:03.745 --> 00:05:07.845
我々はリベッターを取るためにわざわざしないようにXを最適化しようとしていません。

75
00:05:07.845 --> 00:05:09.655
教師付き学習のための、少なくとも、

76
00:05:09.655 --> 00:05:15.605
私たちは、私は明示的DA2を計算スキップするつもりだX.を尊重します。

77
00:05:15.605 --> 00:05:18.110
あなたがしたい場合は、実際に計算することができます

78
00:05:18.110 --> 00:05:20.750
、DA2その後、DZ2を計算することを使用しますが、実際には

79
00:05:20.750 --> 00:05:25.760
あなたが終わるので、あなたは1つのステップにこれらのステップの両方を折りたたむことができ

80
00:05:25.760 --> 00:05:31.715
前と同じDZ2 = A2-Y、で。

81
00:05:31.715 --> 00:05:33.620
そして、あなたも持っています、

82
00:05:33.620 --> 00:05:38.615
私はここで、以下のDW2とDB2を書き留めするつもりです。

83
00:05:38.615 --> 00:05:46.700
あなたは、そのDW2 = DZ2 * A1を持っています

84
00:05:46.700 --> 00:05:52.040
トランスポーズ、およびDB2 = DZ2。

85
00:05:52.040 --> 00:05:55.990
このステップでは、私たちが持っていたロジスティック回帰のために非常に似ています

86
00:05:55.990 --> 00:06:03.550
そのDW =今ことを除いて、DZ * X、

87
00:06:03.550 --> 00:06:08.770
A1は、Xの役割を果たしているとするので、余分な転置があります

88
00:06:08.770 --> 00:06:14.125
資本行列Wと私たちの個々のパラメータWとの間の関係、

89
00:06:14.125 --> 00:06:16.660
転置は右、そこですか？

90
00:06:16.660 --> 00:06:24.370
なぜなら、単一の出力を有するロジスティック回帰の場合= [---] W。

91
00:06:24.370 --> 00:06:26.980
DW2は、一方で、そのようなものです

92
00:06:26.980 --> 00:06:32.440
それはA1のための余分な転置を持っている理由ですので、ここでWは、列ベクトルました

93
00:06:32.440 --> 00:06:36.980
一方、我々はロジスティック回帰のために、ここでXのためではありませんでした。

94
00:06:36.980 --> 00:06:40.335
これは、バックプロパゲーションの半分を完了します。

95
00:06:40.335 --> 00:06:44.045
必要に応じてその後、再び、あなたはDA1を計算することができます。

96
00:06:44.045 --> 00:06:49.440
けれども、実際には、DA1のための計算と

97
00:06:49.440 --> 00:06:52.330
DZ1は、通常、1つのステップなどにまとめられ

98
00:06:52.330 --> 00:06:57.130
あなたが実際に実装しますことは、DZ1 = W2ということです

99
00:06:57.130 --> 00:07:03.480
* DZ2を転置して、要素回

100
00:07:03.480 --> 00:07:10.383
Z1のG1プライムのY社の製品。

101
00:07:10.383 --> 00:07:13.960
そして、ちょうど、寸法のチェックを行うには？

102
00:07:13.960 --> 00:07:19.510
あなたはこのようになり、新たなネットワークを持っている場合は、

103
00:07:19.510 --> 00:07:23.000
もしそうなら、私はYを入れます。

104
00:07:23.000 --> 00:07:28.265
あなたはN0、NX = N0入力機能を持っている場合は、

105
00:07:28.265 --> 00:07:30.230
単位でのN1ヘッド、

106
00:07:30.230 --> 00:07:34.275
そして、N2今のところ。

107
00:07:34.275 --> 00:07:36.740
N2、我々の場合では、

108
00:07:36.740 --> 00:07:38.565
ただ一つの出力ユニット、

109
00:07:38.565 --> 00:07:48.795
次いで、マトリックスW2は（N2、N1）の寸法であり、

110
00:07:48.795 --> 00:07:57.490
Z2したがってDZ2は、一次元で（N2、N1）であることを行っています。

111
00:07:57.490 --> 00:07:59.850
これは本当に私たちは、バイナリ分類を行っている一つ一つになるだろう、

112
00:07:59.850 --> 00:08:04.750
そしてZ1そのためにも

113
00:08:04.750 --> 00:08:10.045
DZ1は右に、一次元でN1をするつもりですか？

114
00:08:10.045 --> 00:08:16.115
任意の変数fooとD fooのために常に同じ寸法を有することに注意してください。

115
00:08:16.115 --> 00:08:20.850
WとDWが常に同じ寸法を有し、同様だからこそ、

116
00:08:20.850 --> 00:08:23.680
BおよびDBとZおよびDZなど。

117
00:08:23.680 --> 00:08:26.895
このすべての寸法が一致することを確認するために、

118
00:08:26.895 --> 00:08:35.430
我々はDZ1 = W2回DZ2を転置することを持っています

119
00:08:35.430 --> 00:08:44.490
その後、これは要素Z1のYの積回G1素数です。

120
00:08:44.490 --> 00:08:47.040
上記の寸法に一致します、

121
00:08:47.040 --> 00:08:52.575
これは、1 = W2転置によってN1になるだろう

122
00:08:52.575 --> 00:08:57.945
私たちは、このN2次元によってN1があるように起こっているので、の転置します。

123
00:08:57.945 --> 00:09:05.790
DZ2は、その後、1次元およびこれによりN2になるだろう

124
00:09:05.790 --> 00:09:07.230
これはZ1と同じ寸法です。

125
00:09:07.230 --> 00:09:11.820
これは、1次元のように要素Y社の製品でもN1です。

126
00:09:11.820 --> 00:09:14.350
寸法は右に、意味を作るのですか？

127
00:09:14.350 --> 00:09:18.330
一次元ベクトルによってN1をすることによって得ることができます

128
00:09:18.330 --> 00:09:23.520
N1によってN2次元マトリックス回N2によってN1ため、製品の

129
00:09:23.520 --> 00:09:28.890
これら二つのことは、あなたに1次元の行列でN1を与え、これはなり

130
00:09:28.890 --> 00:09:34.618
1次元ベクトルによる2つのN1の要素Y社の製品、

131
00:09:34.618 --> 00:09:36.060
そしてその大きさが一致しません。

132
00:09:36.060 --> 00:09:40.620
ワンチップバックの小道具を実装する場合。

133
00:09:40.620 --> 00:09:44.790
あなたは自分の行列の次元が一致することを確認している場合、

134
00:09:44.790 --> 00:09:47.190
あなたはの寸法が何であるかを考え抜きます

135
00:09:47.190 --> 00:09:50.430
W1、W2、Z1、を含む種々のマトリックス

136
00:09:50.430 --> 00:09:54.180
Z2、A1、A2などと念

137
00:09:54.180 --> 00:09:58.642
これらの行列演算の寸法が一致していること、

138
00:09:58.642 --> 00:10:03.390
時には、すでにバック小道具のバグのかなり多くを排除すること。

139
00:10:03.390 --> 00:10:06.960
大丈夫。これは、最終的にはその後、私たちにDZ1を与えると、

140
00:10:06.960 --> 00:10:12.160
ただDW1とDB1をラップするために、

141
00:10:12.160 --> 00:10:13.965
ここでは、私は推測するそれらを書く必要があり、

142
00:10:13.965 --> 00:10:17.200
私は右の若干の右側にスペースを実行していることから、

143
00:10:17.200 --> 00:10:21.965
DW1とDB1は、以下の式で与えられます。

144
00:10:21.965 --> 00:10:25.950
これはDZ1時間X転置に等しくなるようになるだろう

145
00:10:25.950 --> 00:10:28.905
これはDZに等しいことになるだろう。

146
00:10:28.905 --> 00:10:34.045
あなたはこれらの式とこれらの式の間の類似性に気づくかもしれません、

147
00:10:34.045 --> 00:10:37.095
これは実際には偶然ではありませんので、X

148
00:10:37.095 --> 00:10:41.660
Xの転置は、A0転置であるので、A0の役割を果たしています。

149
00:10:41.660 --> 00:10:45.484
これらの方程式は、実際には非常に似ています。

150
00:10:45.484 --> 00:10:50.260
これは、バックプロパゲーションを導出する方法について感を与えます。

151
00:10:50.260 --> 00:10:54.530
私たちは、DZ2、DW2のための6つの主要方程式ここにあります

152
00:10:54.530 --> 00:11:00.190
DB2、DZ1、DW1およびD1。

153
00:11:00.190 --> 00:11:05.767
私はちょうどこれらの6つの方程式を取ると、次のスライドにそれらをコピーしてみましょう。どうぞ。

154
00:11:05.767 --> 00:11:08.950
これまでのところ、我々はバックプロパゲーションを記述する必要があり、

155
00:11:08.950 --> 00:11:13.959
一度に単一の訓練例に訓練されている場合のために、

156
00:11:13.959 --> 00:11:21.530
それは、一度に一つの例に取り組んではなく、驚くことではありません

157
00:11:21.530 --> 00:11:27.810
私たちは、さまざまな訓練例全体でベクトル化したいと思います。

158
00:11:27.810 --> 00:11:30.971
私たちは、繁殖のためにそれを覚えています

159
00:11:30.971 --> 00:11:33.545
私たちは、一度に1つの例で動作しているとき、

160
00:11:33.545 --> 00:11:41.665
Z1のA1が= G1言ったとして、私たちはこのような方程式を持っていました。

161
00:11:41.665 --> 00:11:43.655
ベクトル化するために、

162
00:11:43.655 --> 00:11:51.260
私たちは、Zsを言う取り、それらを積み上げ

163
00:11:51.260 --> 00:12:00.775
このような列Z1Mへと、この資本Z.呼び出します

164
00:12:00.775 --> 00:12:04.960
その後、我々は列に物事を積層しているを発見しました

165
00:12:04.960 --> 00:12:10.240
この資本の大文字のバージョンを定義し、

166
00:12:10.240 --> 00:12:17.093
私たちはその後、ちょうどZ1 = W1 X + Bを持っていました

167
00:12:17.093 --> 00:12:24.700
そしてA1 = Z1のG1、右？

168
00:12:24.700 --> 00:12:28.645
私たちは、それを確認するために、この過程で非常に慎重に表記を定義します

169
00:12:28.645 --> 00:12:35.550
行列の異なる列に例を積み重ねることはすべて、この作業を行うことができます。

170
00:12:35.550 --> 00:12:40.105
それはあなたが慎重に数学を通過する場合ことが判明し、

171
00:12:40.105 --> 00:12:46.645
ベクトル化方程式は次のようにしているので、同じトリックも、バックプロパゲーションのために働きます。

172
00:12:46.645 --> 00:12:52.250
まず、あなたはこれらのDZSを取る場合は、別の訓練例およびスタック用

173
00:12:52.250 --> 00:12:58.339
このためのマトリックスと同じこのため、同一の異なる列としてそれら、

174
00:12:58.339 --> 00:13:03.070
これは、ベクトル化の実装であり、そして、ここでの定義ですが、

175
00:13:03.070 --> 00:13:05.569
またはここにあなたがDW2を計算する方法です。

176
00:13:05.569 --> 00:13:11.130
コスト関数Jがあるため、この余分な1 / Mがあります

177
00:13:11.130 --> 00:13:18.410
このY =損失のMを通して1についての和の1 / M。

178
00:13:18.410 --> 00:13:20.615
リベッターを計算すると、

179
00:13:20.615 --> 00:13:23.885
我々は、我々があったときに私たちがやったように、その1 / Mの余分な用語を持っています

180
00:13:23.885 --> 00:13:27.982
ロジスティック回帰のための日を待って計算。

181
00:13:27.982 --> 00:13:31.790
それはあなたがDB2のために取得、更新です。

182
00:13:31.790 --> 00:13:40.640
次のように再び、DZSの一部とは、次いで1 / MとしてDZ1が計算されます。

183
00:13:40.640 --> 00:13:49.109
もう一度、これが唯一のに対し、以前にY社の製品要素であり、

184
00:13:49.109 --> 00:13:56.595
私たちは、これは1次元ベクトルによってN1だった前のスライドで見ました。

185
00:13:56.595 --> 00:14:03.185
さて、これはM次元の行列によってN1です。

186
00:14:03.185 --> 00:14:09.045
これらのどちらも次元MによってN1あります。

187
00:14:09.045 --> 00:14:19.310
そのアスタリスクは、最終的にはその要素Yの製品であり、だからこそ、

188
00:14:19.310 --> 00:14:21.454
残りの2つの更新。

189
00:14:21.454 --> 00:14:25.836
多分それはあまりにも意外で見てはいけません。

190
00:14:25.836 --> 00:14:29.510
私はそれがあなたのバックプロパゲーションアルゴリズムを導出する方法についていくつかの直感を与える願っています。

191
00:14:29.510 --> 00:14:32.205
機械学習の全てにおいて、

192
00:14:32.205 --> 00:14:34.820
私は、バックプロパゲーションアルゴリズムの導出を考えます

193
00:14:34.820 --> 00:14:38.465
実際に私が見てきた数学の最も複雑な作品の一つです、

194
00:14:38.465 --> 00:14:42.470
それは両方の線形代数を知るだけでなく、必要と

195
00:14:42.470 --> 00:14:46.830
行列の誘導体は、第一原理から、最初からそれを再導出します。

196
00:14:46.830 --> 00:14:50.165
あなたは行列計算の専門家であれば、

197
00:14:50.165 --> 00:14:54.255
このプロセスを使用して、あなたは派生アルゴリズムを自分で証明するかもしれません、

198
00:14:54.255 --> 00:14:57.500
私は深い学習実践者の多くが実際にあると思います

199
00:14:57.500 --> 00:15:01.060
あなたがきた程度のレベルで導出を見てきています

200
00:15:01.060 --> 00:15:04.100
このビデオで見られるし、すでに持ってすることができます

201
00:15:04.100 --> 00:15:08.580
すべての非常に直感と非常に効果的に、このアルゴリズムを実装することができます。

202
00:15:08.580 --> 00:15:10.070
あなたは計算の専門家であれば、

203
00:15:10.070 --> 00:15:13.395
あなたは最初から全部を導き出すことができるかどうかを確認します。

204
00:15:13.395 --> 00:15:15.665
それは数学の非常に困難な作品の一つです。

205
00:15:15.665 --> 00:15:20.010
私は機械学習の全てで見てきた非常に困難な派生の一つ。

206
00:15:20.010 --> 00:15:22.861
いずれにしても、あなたはこれを実装する場合には、

207
00:15:22.861 --> 00:15:27.260
これは動作しますし、私はあなたが調整する十分な直感を持っていると思うし、それが仕事に取り掛かります。

208
00:15:27.260 --> 00:15:30.830
私がしたいだけで1つの最後の詳細があります

209
00:15:30.830 --> 00:15:34.190
あなたは、ニューラルネットワークを実装する前に、あなたと共有、

210
00:15:34.190 --> 00:15:37.720
これはあなたのニューラルネットワークの重みを初期化する方法です。

211
00:15:37.720 --> 00:15:40.600
それはあなたのパラメータを初期化することが判明し、

212
00:15:40.600 --> 00:15:42.560
ランダムにゼロだけにではありません、

213
00:15:42.560 --> 00:15:45.515
あなたのニューラルネットワークを訓練するために非常に重要であることが判明しました。

214
00:15:45.515 --> 00:15:48.000
次のビデオでは、あなたはなぜ表示されます。