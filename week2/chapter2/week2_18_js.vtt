WEBVTT

1
00:00:00.390 --> 00:00:03.860
以前のビデオでは、私が書きました
以下のためのコスト関数のフォームダウン

2
00:00:03.860 --> 00:00:05.230
ロジスティック回帰。

3
00:00:05.230 --> 00:00:09.370
このオプションのビデオでは、私がしたいです
あなたのために迅速な正当性を与えます

4
00:00:09.370 --> 00:00:13.490
我々はのためにそのコスト関数を使用することを好きな理由
ロジスティック回帰。

5
00:00:13.490 --> 00:00:17.709
すぐにロジスティック回帰では、要約すると、

6
00:00:17.709 --> 00:00:23.704
我々は、予測yの帽子は、
W転置X + Bのシグモイドは、あります

7
00:00:23.704 --> 00:00:27.711
どこシグモイドは、このおなじみの機能です。

8
00:00:27.711 --> 00:00:34.353
そして、私たちは解釈したいと言いました
P（| X、Y = 1）として、Yハット。

9
00:00:34.353 --> 00:00:39.776
だから我々は、我々のアルゴリズムがしたいです
チャンスとして出力yハット

10
00:00:39.776 --> 00:00:45.030
すなわち、Y = 1
入力の所与の組は、xがあります。

11
00:00:45.030 --> 00:00:50.090
これを言うためにので、別の方法
もしyが1に等しいということです

12
00:00:50.090 --> 00:00:56.020
その後、Yのチャンスが与えられました
Xは、Yハットに等しいです。

13
00:00:56.020 --> 00:00:59.170
そしてyは、その後、0に等しい場合、逆

14
00:01:00.310 --> 00:01:05.840
yが0だったという可能性は、1- Yの帽子でした
右？

15
00:01:05.840 --> 00:01:09.150
だから、yの帽子はチャンスだった場合、そのY = 1、

16
00:01:09.150 --> 00:01:13.620
その後、1  -  yの帽子をy = 0というチャンスです。

17
00:01:13.620 --> 00:01:18.057
だから、マーは、これらの最後の二つの式を見てみましょう
ちょうど次のスライドにコピーします。

18
00:01:18.057 --> 00:01:22.684
だから、私は何をするつもりはあります
このことは、これらの二つの式を取ります

19
00:01:22.684 --> 00:01:28.010
ため|（X、Y）は、基本的にPを定義します
Y = 0またはy = 1の2例。

20
00:01:28.010 --> 00:01:33.110
そして、これら二つの式を取り、
単一の方程式にそれらをまとめます。

21
00:01:33.110 --> 00:01:37.543
そして、ちょうどyが0のいずれかである必要があります指摘します
または1つのためときバイナリコスト方程式、

22
00:01:37.543 --> 00:01:41.110
したがって、Y = 0または1が2つだけです
可能な場合、すべての権利。

23
00:01:41.110 --> 00:01:44.653
誰かがこれらの二つの式を取るときと
次のようにそれらをまとめます。

24
00:01:44.653 --> 00:01:48.774
私はちょうどそれがどのように見えるかを書き出してみましょう、
それはそのように見えるなぜ我々は説明します。

25
00:01:48.774 --> 00:01:54.040
そう - （ -  Y 1）の電源に（1つのYハット）。

26
00:01:54.040 --> 00:01:58.920
だから、この1行が判明します
一番上の二つの式をまとめました。

27
00:01:58.920 --> 00:02:00.500
私は理由を説明しましょう。

28
00:02:00.500 --> 00:02:04.643
だから、最初のケースでは、
右、Y = 1の仮定？

29
00:02:04.643 --> 00:02:09.562
それでは、このyの場合= 1
用語は、y帽子なってしまいます、

30
00:02:09.562 --> 00:02:13.970
それは1の電源へのyの帽子だから。

31
00:02:13.970 --> 00:02:21.120
この用語は、1- Y帽子なってしまいます
1  -  1の力は、そのためには、0の力です。

32
00:02:21.120 --> 00:02:26.320
しかし、0のパワーには何も
1に等しいので、それが消えます。

33
00:02:26.320 --> 00:02:33.030
だから、この方程式、
ちょうどpと（Y | X）、Y = 1のとき、Yハットを=。

34
00:02:33.030 --> 00:02:37.480
だから、我々が望んでいたまさにです。

35
00:02:37.480 --> 00:02:40.250
今どのように後者の場合について、
何のy = 0の場合？

36
00:02:40.250 --> 00:02:47.057
Y = 0の場合、この式
= Yハット、0〜|上記P（X、Y）は

37
00:02:47.057 --> 00:02:51.920
何でも力に
0のように、1に等しいです。

38
00:02:51.920 --> 00:02:58.267
それは、1回にちょうど等しいです
1- Yのパワーに1- Yハット。

39
00:02:58.267 --> 00:03:02.770
だから、1  -  yは1  -  0であるので、これはちょうど1です。

40
00:03:02.770 --> 00:03:07.610
そして、これは1に等しく、
時間（1- Yハット）= 1- Yハット。

41
00:03:10.700 --> 00:03:17.230
だから、ここで私たちが持っていることのy = 0、
P（Y | X）= 1- yの帽子、

42
00:03:17.230 --> 00:03:21.570
これは、我々は上記たかったまさにです。

43
00:03:21.570 --> 00:03:23.690
だから我々はちょうど示したもの
この式ということです

44
00:03:25.330 --> 00:03:30.331
P（ylx）の正しい定義があります。

45
00:03:30.331 --> 00:03:36.513
さて、最後に、法律のため、
機能は厳密に単調です

46
00:03:36.513 --> 00:03:43.223
増加関数、
あなたは、あなたを与える必要があります最大化しています

47
00:03:43.223 --> 00:03:48.672
P（Y | X）を最適化し、
それP（Y | X）のおコンピュートログ、

48
00:03:48.672 --> 00:03:54.330
それは、Y帽子rのログインに等しいです
1- Yのサブ額面のY 1- Y。

49
00:03:54.330 --> 00:03:59.818
そして、そのためには、Y、ログyの帽子のように簡単になります

50
00:03:59.818 --> 00:04:05.881
+ 1  -  Y回は右、1- Yの帽子を記録しますか？

51
00:04:05.881 --> 00:04:09.832
など
これは実際に損失のマイナスであります

52
00:04:09.832 --> 00:04:14.310
我々は以前に見つけなければならなかった機能。

53
00:04:14.310 --> 00:04:17.470
そして、そこに理由は負の符号があります
あなたは学習を訓練している通常ならば

54
00:04:17.470 --> 00:04:20.460
アルゴリズム、あなたがしたいです
確率を大きくします

55
00:04:20.460 --> 00:04:23.980
ロジスティック回帰のに対して
我々はこれを表現しています。

56
00:04:23.980 --> 00:04:25.820
当社は、損失関数を最小化します。

57
00:04:25.820 --> 00:04:30.640
だから、最小限の損失は、に対応します
確率のログを最大化。

58
00:04:30.640 --> 00:04:33.925
だから、これはどのような損失関数は、
単一の例にように見えます。

59
00:04:33.925 --> 00:04:35.435
どのようにコスト関数について、

60
00:04:35.435 --> 00:04:40.435
上の全体的なコスト関数
m個の例にセット全体のトレーニング？

61
00:04:40.435 --> 00:04:41.385
さんがそれを把握しましょう。

62
00:04:41.385 --> 00:04:45.710
だから、すべての確率
トレーニングセット内のラベル。

63
00:04:45.710 --> 00:04:47.750
少し非公式にこれを書きます。

64
00:04:47.750 --> 00:04:51.945
あなたは、訓練例と仮定した場合
私は、独立して描かれたかIID描かれてきました

65
00:04:51.945 --> 00:04:54.198
同様に独立して分散し、

66
00:04:54.198 --> 00:04:57.810
例の、その後確率
確率の積です。

67
00:04:57.810 --> 00:05:03.143
i = 1からの生成物
m個のP（Y（i））を指定されたX（I）。

68
00:05:03.143 --> 00:05:07.970
だから、あなたが実行したい場合
、最尤推定、右

69
00：05：07.970  - > 00：05：12.476
then you want to maximize the,
最大化パラメータを見つけます

70
00:05:12.476 --> 00:05:15.948
あなたの観測のチャンスと
トレーニングセット。

71
00:05:15.948 --> 00:05:20.200
しかし、これを最大化することと同じです
そう、ログを最大として、

72
00:05:20.200 --> 00:05:22.990
私達はちょうど両側にログを置きます。

73
00:05:22.990 --> 00:05:28.640
だから、ラベルの確率の対数
トレーニングセットでは、に等しく、

74
00:05:28.640 --> 00:05:30.990
製品のログは、ログの合計です。

75
00:05:30.990 --> 00:05:39.000
だからからi = 1から合計です
ログP（Y（i））を指定されたX（I）のM。

76
00:05:39.000 --> 00:05:43.582
そして、我々は以前に持っています
以前に考え出しました

77
00:05:43.582 --> 00:05:47.630
私は、これはYハットの負Lであることがスライド
yの私。

78
00:05:48.850 --> 00:05:55.220
そしてそう統計では、原理があります
最尤の原則と呼ばれます

79
00:05:55.220 --> 00:06:00.720
ただ選択する推定手段、
この事を最大化するパラメータ。

80
00:06:00.720 --> 00:06:04.220
換言すれば、
それは、この事を最大化します。

81
00:06:04.220 --> 00:06:09.510
私からの負の和= 1〜
m個のL（Yハット{I}、Y {I}）と

82
00:06:09.510 --> 00:06:11.840
単に負の符号を動かします
合計外。

83
00:06:11.840 --> 00:06:15.749
だから、これは我々が持っていたコストを正当化します

84
00:06:15.749 --> 00:06:21.235
ロジスティック回帰
これJ本の（B、W）です。

85
00:06:21.235 --> 00:06:27.349
そして、我々は今、最小限にしたいので、
コストの代わりの可能性を最大化、

86
00:06:27.349 --> 00:06:30.095
私たちは、マイナス記号を取り除くようになってきました。

87
00:06:30.095 --> 00:06:35.467
そして、最終的には便宜上、我々が作ります
私たちの量は、より良い規模であることを確認してください、

88
00:06:35.467 --> 00:06:39.310
私達はちょうど1メートルを超える追加します
そこに余分なスケーリング係数。

89
00:06:39.310 --> 00:06:43.960
しかし、その最小化することにより、要約します
このコスト関数J私たちは本当にしている（B、W）

90
00:06:43.960 --> 00:06:48.430
最尤推定を行います
ロジスティック回帰モデルを持ちます。

91
00:06:48.430 --> 00:06:53.120
私たちの仮定の下で
訓練例はIIDた、または

92
00:06:53.120 --> 00:06:55.530
同様に独立して分散。

93
00:06:55.530 --> 00:06:59.550
だから、このビデオを見ていただきありがとうございます、
にもかかわらず、これはオプションです。

94
00:06:59.550 --> 00:07:03.845
私はこれがあなたの理由の感覚を与える願っています
我々は我々が行うコスト関数を使用します

95
00:07:03.845 --> 00:07:05.200
ロジスティック回帰。

96
00:07:05.200 --> 00:07:09.287
ことで、私はあなたに行く願っています
演習、プロの運動と

97
00:07:09.287 --> 00:07:11.277
今週のクイズ。

98
00:07:11.277 --> 00:07:14.735
そして、両方のクイズで最高の幸運、
そして次の演習
